{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My first Autoencoder for Jet compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import uproot\n",
    "import awkward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "I will only use $p_T, \\eta, \\phi \\text{ and } E$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '../../data/'\n",
    "\n",
    "folder15 = 'breynold/user.breynold.data15_13TeV.00284484.physics_Main.DAOD_NTUP_JTRIG_JETM1.r9264_p3083_p3601_j042_tree.root/'\n",
    "file15 = 'user.breynold.18753218._000001.tree.root'\n",
    "folder16 = 'breynold/user.breynold.data16_13TeV.00307656.physics_Main.DAOD_NTUP_JTRIG_JETM1.r9264_p3083_p3601_j042_tree.root/'\n",
    "file16 = 'user.breynold.18797259._000001.tree.root'\n",
    "\n",
    "# Load a ROOT file\n",
    "filePath = path_to_data + folder16 + file16\n",
    "ttree = uproot.open(filePath)['outTree']['nominal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "branchnames = ['nAntiKt4EMTopoJets_Calib2018',\n",
    "               'AntiKt4EMTopoJets_Calib2018_E',\n",
    "               'AntiKt4EMTopoJets_Calib2018_pt',\n",
    "               'AntiKt4EMTopoJets_Calib2018_phi',\n",
    "               'AntiKt4EMTopoJets_Calib2018_eta']\n",
    "\n",
    "jaggedE = ttree.array(branchnames[1])\n",
    "jaggedpT = ttree.array(branchnames[2])\n",
    "jaggedphi = ttree.array(branchnames[3])\n",
    "jaggedeta = ttree.array(branchnames[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20,  9,  9, ...,  5, 18, 11])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaggedE.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([212.2173  , 175.15614 ,  64.451935, ...,  24.369474,  13.941364,\n",
       "        60.927433], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaggedE.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leading(jaggedX):\n",
    "    return jaggedX[jaggedX.counts > 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "leading_E = get_leading(jaggedE)\n",
    "leading_pT = get_leading(jaggedpT)\n",
    "leading_phi = get_leading(jaggedphi)\n",
    "leading_eta = get_leading(jaggedeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1937902,) (1937902,) (1937902,) (1937902,)\n"
     ]
    }
   ],
   "source": [
    "print(leading_E.shape, leading_eta.shape, leading_phi.shape, leading_pT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = {'pT': leading_pT, 'eta': leading_eta, 'phi': leading_phi, 'E': leading_E})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pT</th>\n",
       "      <th>eta</th>\n",
       "      <th>phi</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>161.850494</td>\n",
       "      <td>-0.764774</td>\n",
       "      <td>2.287350</td>\n",
       "      <td>212.217300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>164.702454</td>\n",
       "      <td>0.205651</td>\n",
       "      <td>-1.074816</td>\n",
       "      <td>169.021805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>405.421387</td>\n",
       "      <td>-0.064094</td>\n",
       "      <td>-2.324020</td>\n",
       "      <td>407.661316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>139.671234</td>\n",
       "      <td>-0.289339</td>\n",
       "      <td>-2.052494</td>\n",
       "      <td>145.860703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>227.195618</td>\n",
       "      <td>2.158644</td>\n",
       "      <td>-1.864455</td>\n",
       "      <td>996.913025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>180.480667</td>\n",
       "      <td>1.684722</td>\n",
       "      <td>-1.049987</td>\n",
       "      <td>503.476410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>39.454185</td>\n",
       "      <td>-0.305395</td>\n",
       "      <td>0.755678</td>\n",
       "      <td>41.943340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>202.920883</td>\n",
       "      <td>1.583752</td>\n",
       "      <td>-0.301926</td>\n",
       "      <td>515.302856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>263.867432</td>\n",
       "      <td>-0.141594</td>\n",
       "      <td>-2.308791</td>\n",
       "      <td>267.712372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>234.460327</td>\n",
       "      <td>-2.949176</td>\n",
       "      <td>2.114750</td>\n",
       "      <td>2244.307617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pT       eta       phi            E\n",
       "0  161.850494 -0.764774  2.287350   212.217300\n",
       "1  164.702454  0.205651 -1.074816   169.021805\n",
       "2  405.421387 -0.064094 -2.324020   407.661316\n",
       "3  139.671234 -0.289339 -2.052494   145.860703\n",
       "4  227.195618  2.158644 -1.864455   996.913025\n",
       "5  180.480667  1.684722 -1.049987   503.476410\n",
       "6   39.454185 -0.305395  0.755678    41.943340\n",
       "7  202.920883  1.583752 -0.301926   515.302856\n",
       "8  263.867432 -0.141594 -2.308791   267.712372\n",
       "9  234.460327 -2.949176  2.114750  2244.307617"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = len(df.loc[0])\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1550321, 4) (387581, 4)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features\n",
    "train_mean = train.mean()\n",
    "train_std = train.std()\n",
    "\n",
    "train = (train - train_mean) / train_std\n",
    "test = (test - train_mean) / train_std  # Is this the right way to normalize? (only using train mean and std to normalize both train and test)\n",
    "\n",
    "train_x = train\n",
    "test_x = test\n",
    "train_y = train_x  # y = x since we are building and AE\n",
    "test_y = test_x\n",
    "\n",
    "train_ds = TensorDataset(torch.tensor(train_x.values), torch.tensor(train_y.values))\n",
    "valid_ds = TensorDataset(torch.tensor(test_x.values), torch.tensor(test_y.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_big = nn.Sequential(\n",
    "    nn.Linear(n_features, 8),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(8, 6),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(6, 4),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(4, 6),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(6, 8),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(8, n_features),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(n_features, 4),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(4, 4),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(4, n_features),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some helper functions\n",
    "\n",
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )\n",
    "\n",
    "\n",
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)\n",
    "\n",
    "\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)  # MSE-Loss\n",
    "        if(epoch % 1 == 0):\n",
    "            print(epoch, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64  # batch size\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0010494361593958433\n",
      "1 0.0004540579605446538\n",
      "2 0.00034858031049211024\n",
      "3 0.00026986450002987756\n",
      "4 0.0004867862588560652\n",
      "5 0.00020429829266885958\n",
      "6 0.00022113420253831216\n",
      "7 0.00018123884706553294\n",
      "8 0.00013537716324884424\n",
      "9 0.0014280721862093072\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "loss_func = nn.MSELoss()\n",
    "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inp: tensor([ 1.6863, -0.7095,  1.6946,  0.2721])\n",
      "Out: tensor([ 1.6963, -0.7004,  1.7025,  0.2879], grad_fn=<AddBackward0>)\n",
      " \n",
      "Inp: tensor([ 0.1766, -0.1649, -0.0310, -0.5931])\n",
      "Out: tensor([ 0.1274, -0.1661, -0.0452, -0.6528], grad_fn=<AddBackward0>)\n",
      " \n",
      "Inp: tensor([-0.3746,  0.6508,  1.3037, -0.5510])\n",
      "Out: tensor([-0.4260,  0.6506,  1.2878, -0.6035], grad_fn=<AddBackward0>)\n",
      " \n",
      "Inp: tensor([-0.3711, -0.0072,  1.0894, -0.7293])\n",
      "Out: tensor([-0.4295, -0.0094,  1.0705, -0.7884], grad_fn=<AddBackward0>)\n",
      " \n",
      "Inp: tensor([-0.7818, -0.3965,  1.1572, -0.7662])\n",
      "Out: tensor([-0.8466, -0.4023,  1.1318, -0.8270], grad_fn=<AddBackward0>)\n",
      " \n",
      "Inp: tensor([0.4060, 1.5628, 1.4620, 1.8385])\n",
      "Out: tensor([0.4181, 1.5393, 1.5021, 1.8960], grad_fn=<AddBackward0>)\n",
      " \n",
      "Inp: tensor([-0.0816, -0.7146, -1.2172, -0.3813])\n",
      "Out: tensor([-0.1268, -0.7154, -1.2359, -0.4392], grad_fn=<AddBackward0>)\n",
      " \n",
      "Inp: tensor([ 0.4208,  0.0398, -1.2887, -0.5597])\n",
      "Out: tensor([ 0.3739,  0.0425, -1.3057, -0.6094], grad_fn=<AddBackward0>)\n",
      " \n",
      "Inp: tensor([ 0.0139,  1.3978, -1.7089,  0.7964])\n",
      "Out: tensor([-0.0037,  1.3891, -1.7039,  0.7762], grad_fn=<AddBackward0>)\n",
      " \n",
      "Inp: tensor([ 1.8584,  0.4536, -0.0703, -0.0505])\n",
      "Out: tensor([ 1.8647,  0.4558, -0.0693, -0.0586], grad_fn=<AddBackward0>)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for ii in np.arange(100, 110):\n",
    "    data = valid_ds.tensors[0][ii]\n",
    "    pred = model(data)\n",
    "    print('Inp:', data)\n",
    "    print('Out:', pred)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train big model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0007220761639093102\n",
      "1 0.0005584392987280982\n",
      "2 0.00032148699721384167\n",
      "3 0.0002659424027709085\n",
      "4 0.00040910318819990164\n",
      "5 0.00028860363617066976\n",
      "6 0.0003309040378328268\n",
      "7 0.0003966791239062391\n",
      "8 0.00017902772095663744\n",
      "9 0.00023927971482582953\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "loss_func = nn.MSELoss()\n",
    "opt = optim.Adam(model_big.parameters(), lr=1e-3)\n",
    "fit(epochs, model_big, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inp: tensor([ 1.6863, -0.7095,  1.6946,  0.2721])\n",
      "Out: tensor([ 1.6891, -0.7021,  1.7048,  0.2885], grad_fn=<AddBackward0>)\n",
      " \n",
      "Inp: tensor([ 0.1766, -0.1649, -0.0310, -0.5931])\n",
      "Out: tensor([ 0.1732, -0.1706, -0.0303, -0.5954], grad_fn=<AddBackward0>)\n",
      " \n",
      "Inp: tensor([-0.3746,  0.6508,  1.3037, -0.5510])\n",
      "Out: tensor([-0.3743,  0.6546,  1.3109, -0.5559], grad_fn=<AddBackward0>)\n",
      " \n",
      "Inp: tensor([-0.3711, -0.0072,  1.0894, -0.7293])\n",
      "Out: tensor([-0.3758, -0.0057,  1.0981, -0.7372], grad_fn=<AddBackward0>)\n",
      " \n",
      "Inp: tensor([-0.7818, -0.3965,  1.1572, -0.7662])\n",
      "Out: tensor([-0.7852, -0.3941,  1.1631, -0.7795], grad_fn=<AddBackward0>)\n",
      " \n",
      "Inp: tensor([0.4060, 1.5628, 1.4620, 1.8385])\n",
      "Out: tensor([0.4307, 1.5773, 1.4798, 1.8541], grad_fn=<AddBackward0>)\n",
      " \n",
      "Inp: tensor([-0.0816, -0.7146, -1.2172, -0.3813])\n",
      "Out: tensor([-0.0888, -0.7210, -1.2308, -0.3745], grad_fn=<AddBackward0>)\n",
      " \n",
      "Inp: tensor([ 0.4208,  0.0398, -1.2887, -0.5597])\n",
      "Out: tensor([ 0.4208,  0.0341, -1.3000, -0.5436], grad_fn=<AddBackward0>)\n",
      " \n",
      "Inp: tensor([ 0.0139,  1.3978, -1.7089,  0.7964])\n",
      "Out: tensor([ 0.0192,  1.3837, -1.7145,  0.8127], grad_fn=<AddBackward0>)\n",
      " \n",
      "Inp: tensor([ 1.8584,  0.4536, -0.0703, -0.0505])\n",
      "Out: tensor([ 1.8927,  0.4368, -0.0583, -0.0306], grad_fn=<AddBackward0>)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for ii in np.arange(100, 110):\n",
    "    data = valid_ds.tensors[0][ii]\n",
    "    pred = model_big(data)\n",
    "    print('Inp:', data)\n",
    "    print('Out:', pred)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.7 (fastairoot)",
   "language": "python",
   "name": "fastairoot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
