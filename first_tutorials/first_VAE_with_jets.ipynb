{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My first Variational Autoencoder for Jet compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import uproot\n",
    "import awkward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "I will only use $p_T, \\eta, \\phi \\text{ and } E$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '../../data/'\n",
    "\n",
    "folder15 = 'breynold/user.breynold.data15_13TeV.00284484.physics_Main.DAOD_NTUP_JTRIG_JETM1.r9264_p3083_p3601_j042_tree.root/'\n",
    "file15 = 'user.breynold.18753218._000001.tree.root'\n",
    "folder16 = 'breynold/user.breynold.data16_13TeV.00307656.physics_Main.DAOD_NTUP_JTRIG_JETM1.r9264_p3083_p3601_j042_tree.root/'\n",
    "file16 = 'user.breynold.18797259._000001.tree.root'\n",
    "\n",
    "# Load a ROOT file\n",
    "filePath = path_to_data + folder16 + file16\n",
    "ttree = uproot.open(filePath)['outTree']['nominal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "branchnames = ['nAntiKt4EMTopoJets_Calib2018',\n",
    "               'AntiKt4EMTopoJets_Calib2018_E',\n",
    "               'AntiKt4EMTopoJets_Calib2018_pt',\n",
    "               'AntiKt4EMTopoJets_Calib2018_phi',\n",
    "               'AntiKt4EMTopoJets_Calib2018_eta']\n",
    "\n",
    "jaggedE = ttree.array(branchnames[1])\n",
    "jaggedpT = ttree.array(branchnames[2])\n",
    "jaggedphi = ttree.array(branchnames[3])\n",
    "jaggedeta = ttree.array(branchnames[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leading(jaggedX):\n",
    "    return jaggedX[jaggedX.counts > 1, 0]\n",
    "\n",
    "leading_E = get_leading(jaggedE)\n",
    "leading_pT = get_leading(jaggedpT)\n",
    "leading_phi = get_leading(jaggedphi)\n",
    "leading_eta = get_leading(jaggedeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1937902,) (1937902,) (1937902,) (1937902,)\n"
     ]
    }
   ],
   "source": [
    "print(leading_E.shape, leading_eta.shape, leading_phi.shape, leading_pT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = {'pT': leading_pT, 'eta': leading_eta, 'phi': leading_phi, 'E': leading_E})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pT</th>\n",
       "      <th>eta</th>\n",
       "      <th>phi</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>161.850494</td>\n",
       "      <td>-0.764774</td>\n",
       "      <td>2.287350</td>\n",
       "      <td>212.217300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>164.702454</td>\n",
       "      <td>0.205651</td>\n",
       "      <td>-1.074816</td>\n",
       "      <td>169.021805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>405.421387</td>\n",
       "      <td>-0.064094</td>\n",
       "      <td>-2.324020</td>\n",
       "      <td>407.661316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>139.671234</td>\n",
       "      <td>-0.289339</td>\n",
       "      <td>-2.052494</td>\n",
       "      <td>145.860703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>227.195618</td>\n",
       "      <td>2.158644</td>\n",
       "      <td>-1.864455</td>\n",
       "      <td>996.913025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>180.480667</td>\n",
       "      <td>1.684722</td>\n",
       "      <td>-1.049987</td>\n",
       "      <td>503.476410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>39.454185</td>\n",
       "      <td>-0.305395</td>\n",
       "      <td>0.755678</td>\n",
       "      <td>41.943340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>202.920883</td>\n",
       "      <td>1.583752</td>\n",
       "      <td>-0.301926</td>\n",
       "      <td>515.302856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>263.867432</td>\n",
       "      <td>-0.141594</td>\n",
       "      <td>-2.308791</td>\n",
       "      <td>267.712372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>234.460327</td>\n",
       "      <td>-2.949176</td>\n",
       "      <td>2.114750</td>\n",
       "      <td>2244.307617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pT       eta       phi            E\n",
       "0  161.850494 -0.764774  2.287350   212.217300\n",
       "1  164.702454  0.205651 -1.074816   169.021805\n",
       "2  405.421387 -0.064094 -2.324020   407.661316\n",
       "3  139.671234 -0.289339 -2.052494   145.860703\n",
       "4  227.195618  2.158644 -1.864455   996.913025\n",
       "5  180.480667  1.684722 -1.049987   503.476410\n",
       "6   39.454185 -0.305395  0.755678    41.943340\n",
       "7  202.920883  1.583752 -0.301926   515.302856\n",
       "8  263.867432 -0.141594 -2.308791   267.712372\n",
       "9  234.460327 -2.949176  2.114750  2244.307617"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = len(df.loc[0])\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1550321, 4) (387581, 4)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features\n",
    "train_mean = train.mean()\n",
    "train_std = train.std()\n",
    "\n",
    "train = (train - train_mean) / train_std\n",
    "test = (test - train_mean) / train_std  # Is this the right way to normalize? (only using train mean and std to normalize both train and test)\n",
    "\n",
    "train_x = train\n",
    "test_x = test\n",
    "train_y = train_x  # y = x since we are building and AE\n",
    "test_y = test_x\n",
    "\n",
    "train_ds = TensorDataset(torch.tensor(train_x.values), torch.tensor(train_y.values))\n",
    "valid_ds = TensorDataset(torch.tensor(test_x.values), torch.tensor(test_y.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = n_features\n",
    "representation_size = input_size - 1\n",
    "intermediate_size = 6\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        self.en1 = nn.Linear(input_size, intermediate_size)\n",
    "        self.en_mu = nn.Linear(intermediate_size, representation_size)\n",
    "        self.en_std = nn.Linear(intermediate_size, representation_size)\n",
    "        self.de1 = nn.Linear(representation_size, intermediate_size)\n",
    "        self.de2 = nn.Linear(intermediate_size, input_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def encode(self, x):\n",
    "        \"\"\"Encode a batch of samples, and return posterior parameters for each point.\"\"\"\n",
    "        h1 = self.tanh(self.en1(x))\n",
    "        return self.en_mu(h1), self.en_std(h1)\n",
    "    \n",
    "    def decode(self, z):\n",
    "        \"\"\"Decode a batch of latent variables\"\"\"\n",
    "        \n",
    "        h2 = self.tanh(self.de1(z))\n",
    "        return self.de2(h2)\n",
    "#        return self.sigmoid(self.de2(h2))\n",
    "    \n",
    "    def reparam(self, mu, logvar):\n",
    "        \"\"\"Reparameterisation trick to sample z values. \n",
    "        This is stochastic during training,  and returns the mode during evaluation.\"\"\"\n",
    "        \n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "            \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Takes a batch of samples, encodes them, and then decodes them again to compare.\"\"\"\n",
    "        mu, logvar = self.encode(x.view(-1, input_size))\n",
    "        z = self.reparam(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "    \n",
    "    def loss(self, reconstruction, x, mu, logvar):\n",
    "        \"\"\"ELBO assuming entries of x are binary variables, with closed form KLD.\"\"\"\n",
    "        \n",
    "        #bce = torch.nn.functional.binary_cross_entropy(reconstruction, x.view(-1, input_size))\n",
    "        mse = nn.functional.mse_loss(reconstruction, x)\n",
    "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        # Normalise by same number of elements as in reconstruction\n",
    "        KLD /= x.view(-1, input_size).data.shape[0] * input_size\n",
    "\n",
    "        return KLD + mse #+bce\n",
    "    \n",
    "    def get_z(self, x):\n",
    "        \"\"\"Encode a batch of data points, x, into their z representations.\"\"\"\n",
    "        \n",
    "        mu, logvar = self.encode(x.view(-1, input_size))\n",
    "        return self.reparam(mu, logvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some helper functions\n",
    "\n",
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )\n",
    "\n",
    "\n",
    "def loss_batch(model, xb, yb, opt=None):\n",
    "    #loss = loss_func(model(xb), yb)\n",
    "    data = Variable(xb, requires_grad=False)\n",
    "    reco_b, mu, logvar = model(data)\n",
    "    loss = model.loss(reco_b, xb, mu, logvar)\n",
    "    \n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)\n",
    "\n",
    "\n",
    "def fit(epochs, model, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)  # MSE-Loss\n",
    "        if(epoch % 1 == 0):\n",
    "            print('epoch: ' + str(epoch) + ',', 'validation loss: ' + str(val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64  # batch size\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, validation loss: 0.5196816085694753\n",
      "epoch: 1, validation loss: 0.5108155167093494\n",
      "epoch: 2, validation loss: 0.5154185904126377\n",
      "epoch: 3, validation loss: 0.5132839906139113\n",
      "epoch: 4, validation loss: 0.5160012102922058\n",
      "epoch: 5, validation loss: 0.5144948043346376\n",
      "epoch: 6, validation loss: 0.5122744664231682\n",
      "epoch: 7, validation loss: 0.5143750624095714\n",
      "epoch: 8, validation loss: 0.5143660303076657\n",
      "epoch: 9, validation loss: 0.5159009462526689\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "fit(epochs, model, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inp: tensor([ 1.6863, -0.7095,  1.6946,  0.2721])\n",
      "Out: (tensor([[ 0.8634, -0.3817,  0.8849, -0.1324]], grad_fn=<AddmmBackward>), tensor([[-1.1585, -0.4377, -1.1141]], grad_fn=<AddmmBackward>), tensor([[-1.1476, -1.3939, -0.9113]], grad_fn=<AddmmBackward>))\n",
      " \n",
      "Inp: tensor([ 0.1766, -0.1649, -0.0310, -0.5931])\n",
      "Out: (tensor([[-0.0484, -0.0383, -0.0242, -0.5046]], grad_fn=<AddmmBackward>), tensor([[ 0.0388, -0.0627,  0.0279]], grad_fn=<AddmmBackward>), tensor([[-0.7765, -1.2031, -0.5871]], grad_fn=<AddmmBackward>))\n",
      " \n",
      "Inp: tensor([-0.3746,  0.6508,  1.3037, -0.5510])\n",
      "Out: (tensor([[-0.2542,  0.3137,  0.8408, -0.4866]], grad_fn=<AddmmBackward>), tensor([[ 0.4190,  0.3437, -0.9271]], grad_fn=<AddmmBackward>), tensor([[-0.7277, -1.2477, -0.8198]], grad_fn=<AddmmBackward>))\n",
      " \n",
      "Inp: tensor([-0.3711, -0.0072,  1.0894, -0.7293])\n",
      "Out: (tensor([[-0.2641,  0.0272,  0.7654, -0.5709]], grad_fn=<AddmmBackward>), tensor([[ 0.4449,  0.0076, -0.8131]], grad_fn=<AddmmBackward>), tensor([[-0.7119, -1.1983, -0.7654]], grad_fn=<AddmmBackward>))\n",
      " \n",
      "Inp: tensor([-0.7818, -0.3965,  1.1572, -0.7662])\n",
      "Out: (tensor([[-0.4054, -0.1351,  0.7926, -0.6215]], grad_fn=<AddmmBackward>), tensor([[ 0.7013, -0.1812, -0.8498]], grad_fn=<AddmmBackward>), tensor([[-0.6731, -1.1981, -0.7777]], grad_fn=<AddmmBackward>))\n",
      " \n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for ii in np.arange(100, 105):\n",
    "    data = valid_ds.tensors[0][ii]\n",
    "    pred = model(data)\n",
    "    print('Inp:', data)\n",
    "    print('Out:', pred)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = (4000, 4010)  # Choose events to compare\n",
    "#Get some data for comparison\n",
    "data = valid_ds.tensors[0][idxs[0]:idxs[1]]\n",
    "pred = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1568,  0.2490,  0.7704, -0.4352],\n",
       "        [-0.0594, -0.1868, -0.8088, -0.3842],\n",
       "        [-0.3419,  0.0142,  0.0736, -0.4948],\n",
       "        [-0.2194, -0.2284, -0.8096, -0.4249],\n",
       "        [-0.3937,  0.1628,  0.8632, -0.5142],\n",
       "        [ 0.6288,  0.0240,  0.6771, -0.2426],\n",
       "        [-0.2346, -0.0035,  0.5084, -0.4622],\n",
       "        [-0.3577,  0.0455, -0.6020, -0.5001],\n",
       "        [-0.3641, -0.9947,  0.8514,  0.7858],\n",
       "        [-0.3432, -0.9999,  0.8278,  0.9889]], grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-7bd589ee1bcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfigsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Output'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_style\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinewd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Input'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_style\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinewd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfontsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not tuple"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 288x216 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot input on top of output\n",
    "linewd = 3\n",
    "line_style = ['-', '--']\n",
    "colors = ['c', 'orange']\n",
    "fontsz = 16\n",
    "figsz = (4, 3)\n",
    "for kk in np.arange(4):\n",
    "    plt.figure(kk, figsize=figsz)\n",
    "    plt.plot(pred[:, kk], color=colors[0], label='Output', linestyle=line_style[0], linewidth=linewd)\n",
    "    plt.plot(data[:, kk], color=colors[1], label='Input', linestyle=line_style[1], linewidth=linewd)\n",
    "    plt.title(df.columns[kk], fontsize=fontsz)\n",
    "    plt.xlabel('Event', fontsize=fontsz)\n",
    "    plt.ylabel(df.columns[kk], fontsize=fontsz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0323,  0.7058,  1.1086, -0.3939],\n",
       "        [ 0.1698, -0.6500, -1.3607, -0.3466],\n",
       "        [-0.4372, -0.0921,  0.0349, -0.7382],\n",
       "        [-0.1991, -0.7556, -1.3839, -0.3895],\n",
       "        [-0.6349,  0.5452,  1.7008, -0.6860],\n",
       "        [ 1.4177, -0.0505,  0.8754, -0.3445],\n",
       "        [-0.1545, -0.1721,  0.5062, -0.6675],\n",
       "        [-0.4818,  0.0487, -0.7327, -0.7531],\n",
       "        [-0.5573, -1.7204,  1.6769,  1.1776],\n",
       "        [-0.2746, -1.9680,  1.5403,  2.9611]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = test[idxs[0]:idxs[1]].values\n",
    "data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.1568,  0.2490,  0.7704, -0.4352],\n",
       "         [-0.0594, -0.1868, -0.8088, -0.3842],\n",
       "         [-0.3419,  0.0142,  0.0736, -0.4948],\n",
       "         [-0.2194, -0.2284, -0.8096, -0.4249],\n",
       "         [-0.3937,  0.1628,  0.8632, -0.5142],\n",
       "         [ 0.6288,  0.0240,  0.6771, -0.2426],\n",
       "         [-0.2346, -0.0035,  0.5084, -0.4622],\n",
       "         [-0.3577,  0.0455, -0.6020, -0.5001],\n",
       "         [-0.3641, -0.9947,  0.8514,  0.7858],\n",
       "         [-0.3432, -0.9999,  0.8278,  0.9889]], grad_fn=<TanhBackward>),\n",
       " tensor([[ 0.8532,  0.1347, -0.3429],\n",
       "         [-0.9502, -0.1197,  0.3582],\n",
       "         [ 0.0413,  0.4601,  0.0386],\n",
       "         [-0.9644,  0.1735,  0.4069],\n",
       "         [ 1.0729,  0.6124, -0.2068],\n",
       "         [ 0.7463, -0.9481,  0.0175],\n",
       "         [ 0.4565,  0.2650,  0.0690],\n",
       "         [-0.6096,  0.4706, -0.0095],\n",
       "         [ 1.0724,  0.2565,  1.5770],\n",
       "         [ 1.0277, -0.0427,  1.9915]], grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.7347, -0.4488, -1.0043],\n",
       "         [-0.7437, -0.4104, -1.0483],\n",
       "         [-0.7366, -0.4796, -1.0685],\n",
       "         [-0.7470, -0.4381, -1.0330],\n",
       "         [-0.7330, -0.5184, -1.0333],\n",
       "         [-0.7179, -0.6925, -1.0759],\n",
       "         [-0.7324, -0.4394, -1.0918],\n",
       "         [-0.7409, -0.4919, -1.0703],\n",
       "         [-0.7503, -0.5145, -1.2994],\n",
       "         [-0.7427, -0.4905, -1.9336]], grad_fn=<AddmmBackward>))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = (4000, 4010)  # Choose events to compare\n",
    "#Get some data for comparison\n",
    "data = test\n",
    "pred = model(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.7 (fastairoot)",
   "language": "python",
   "name": "fastairoot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
