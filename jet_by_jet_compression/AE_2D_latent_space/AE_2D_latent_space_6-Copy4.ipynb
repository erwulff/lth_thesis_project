{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jet Compression using an Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "BIN = '../../'\n",
    "sys.path.append(BIN)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from my_nn_modules import AE_big, get_data, fit\n",
    "\n",
    "import my_matplotlib_style as ms\n",
    "mpl.rc_file(BIN + 'my_matplotlib_rcparams')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "force_cpu = False\n",
    "\n",
    "if force_cpu:\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pT</th>\n",
       "      <th>eta</th>\n",
       "      <th>phi</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1367643</td>\n",
       "      <td>300.752869</td>\n",
       "      <td>0.118391</td>\n",
       "      <td>-1.460827</td>\n",
       "      <td>303.719818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1739612</td>\n",
       "      <td>79.819145</td>\n",
       "      <td>4.535507</td>\n",
       "      <td>-1.185196</td>\n",
       "      <td>3722.832764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>546066</td>\n",
       "      <td>220.472305</td>\n",
       "      <td>1.314261</td>\n",
       "      <td>-0.943992</td>\n",
       "      <td>440.195190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213212</td>\n",
       "      <td>74.533775</td>\n",
       "      <td>0.010658</td>\n",
       "      <td>-0.424795</td>\n",
       "      <td>74.770332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150544</td>\n",
       "      <td>220.668121</td>\n",
       "      <td>2.432910</td>\n",
       "      <td>-2.308348</td>\n",
       "      <td>1266.681030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>574837</td>\n",
       "      <td>159.841782</td>\n",
       "      <td>0.731125</td>\n",
       "      <td>-1.150598</td>\n",
       "      <td>207.133514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1171687</td>\n",
       "      <td>306.125305</td>\n",
       "      <td>0.702473</td>\n",
       "      <td>0.437615</td>\n",
       "      <td>385.713013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1608254</td>\n",
       "      <td>189.011673</td>\n",
       "      <td>-1.387443</td>\n",
       "      <td>0.490634</td>\n",
       "      <td>403.126709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1618830</td>\n",
       "      <td>194.996719</td>\n",
       "      <td>-1.022815</td>\n",
       "      <td>-1.560437</td>\n",
       "      <td>306.534515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>637947</td>\n",
       "      <td>186.887146</td>\n",
       "      <td>-0.621282</td>\n",
       "      <td>-0.465523</td>\n",
       "      <td>226.002701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pT       eta       phi            E\n",
       "1367643  300.752869  0.118391 -1.460827   303.719818\n",
       "1739612   79.819145  4.535507 -1.185196  3722.832764\n",
       "546066   220.472305  1.314261 -0.943992   440.195190\n",
       "213212    74.533775  0.010658 -0.424795    74.770332\n",
       "150544   220.668121  2.432910 -2.308348  1266.681030\n",
       "574837   159.841782  0.731125 -1.150598   207.133514\n",
       "1171687  306.125305  0.702473  0.437615   385.713013\n",
       "1608254  189.011673 -1.387443  0.490634   403.126709\n",
       "1618830  194.996719 -1.022815 -1.560437   306.534515\n",
       "637947   186.887146 -0.621282 -0.465523   226.002701"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "train = pd.read_pickle(BIN + 'processed_data/train.pkl')\n",
    "test = pd.read_pickle(BIN + 'processed_data/test.pkl')\n",
    "\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing and splitting into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "train_mean = train.mean()\n",
    "train_std = train.std()\n",
    "\n",
    "train = (train - train_mean) / train_std\n",
    "# Is this the right way to normalize? (only using train mean and std to normalize both train and test)\n",
    "test = (test - train_mean) / train_std\n",
    "\n",
    "train_x = train\n",
    "test_x = test\n",
    "train_y = train_x  # y = x since we are building and AE\n",
    "test_y = test_x\n",
    "\n",
    "train_ds = TensorDataset(torch.tensor(train_x.values), torch.tensor(train_y.values))\n",
    "valid_ds = TensorDataset(torch.tensor(test_x.values), torch.tensor(test_y.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(input, target, size_average=None, reduce=None, reduction='mean'):\n",
    "    # type: (Tensor, Tensor, Optional[bool], Optional[bool], str) -> Tensor\n",
    "    r\"\"\"mse_loss(input, target, size_average=None, reduce=None, reduction='mean') -> Tensor\n",
    "\n",
    "    Measures the element-wise mean squared error.\n",
    "\n",
    "    See :class:`~torch.nn.MSELoss` for details.\n",
    "    \"\"\"\n",
    "    if not (target.size() == input.size()):\n",
    "        warnings.warn(\"Using a target size ({}) that is different to the input size ({}). \"\n",
    "                      \"This will likely lead to incorrect results due to broadcasting. \"\n",
    "                      \"Please ensure they have the same size.\".format(target.size(), input.size()),\n",
    "                      stacklevel=2)\n",
    "    if size_average is not None or reduce is not None:\n",
    "        reduction = _Reduction.legacy_get_string(size_average, reduce)\n",
    "\n",
    "    ret = (input - target) ** 2\n",
    "    factor = torch.full(ret.size(), 1)\n",
    "    factor[:, 2] = 2.4\n",
    "    ret = ret * factor\n",
    "    if reduction != 'none':\n",
    "        ret = torch.mean(ret) if reduction == 'mean' else torch.sum(ret)\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 256  # batch size\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "loss_func = nn.MSELoss()\n",
    "loss_func = mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE_2D_v50(nn.Module):\n",
    "    def __init__(self, n_features=4):\n",
    "        super(AE_2D_v50, self).__init__()\n",
    "        self.en1 = nn.Linear(n_features, 50)\n",
    "        self.en2 = nn.Linear(50, 50)\n",
    "        self.en3 = nn.Linear(50, 50)\n",
    "        self.en4 = nn.Linear(50, 2)\n",
    "        self.de1 = nn.Linear(2, 50)\n",
    "        self.de2 = nn.Linear(50, 50)\n",
    "        self.de3 = nn.Linear(50, 50)\n",
    "        self.de4 = nn.Linear(50, n_features)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.en4(self.tanh(self.en3(self.tanh(self.en2(self.tanh(self.en1(x)))))))\n",
    "\n",
    "    def decode(self, x):\n",
    "        return self.de4(self.tanh(self.de3(self.tanh(self.de2(self.tanh(self.de1(self.tanh(x))))))))\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        return self.decode(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = len(train.loc[0])\n",
    "model = AE_2D_v50(n_features=n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting learning rate to 1.0e-03\n",
      "Epoch 0: Validation loss = 0.14021562552491057 Time: 0:01:49.180899\n",
      "Epoch 1: Validation loss = 0.09522993714742271 Time: 0:03:11.348662\n",
      "Epoch 2: Validation loss = 0.08047853383775445 Time: 0:04:33.830111\n",
      "Epoch 3: Validation loss = 0.06966366652193334 Time: 0:05:58.307561\n",
      "Epoch 4: Validation loss = 0.0596635808708634 Time: 0:07:19.318621\n",
      "Epoch 5: Validation loss = 0.05444515463526372 Time: 0:08:43.931103\n",
      "Epoch 6: Validation loss = 0.05090185806827174 Time: 0:10:11.509697\n",
      "Epoch 7: Validation loss = 0.04762768829340659 Time: 0:11:33.200783\n",
      "Epoch 8: Validation loss = 0.04407361683317724 Time: 0:13:03.464044\n",
      "Epoch 9: Validation loss = 0.043304497754316905 Time: 0:14:26.417064\n",
      "Epoch 10: Validation loss = 0.041591219134227066 Time: 0:15:54.324062\n",
      "Epoch 11: Validation loss = 0.05660663180975356 Time: 0:17:24.931587\n",
      "Epoch 12: Validation loss = 0.03814534394399325 Time: 0:18:51.464899\n",
      "Epoch 13: Validation loss = 0.03848159636032972 Time: 0:20:09.918563\n",
      "Epoch 14: Validation loss = 0.035150197525289785 Time: 0:21:32.069537\n",
      "Epoch 15: Validation loss = 0.03569870200999739 Time: 0:22:52.406002\n",
      "Epoch 16: Validation loss = 0.03436534355290912 Time: 0:24:15.817127\n",
      "Epoch 17: Validation loss = 0.0347825834459595 Time: 0:25:33.227223\n",
      "Epoch 18: Validation loss = 0.03373540661362033 Time: 0:27:01.978911\n",
      "Epoch 19: Validation loss = 0.03518914460490462 Time: 0:28:35.575549\n",
      "Epoch 20: Validation loss = 0.033505152895338494 Time: 0:30:11.506259\n",
      "Epoch 21: Validation loss = 0.03378851581352711 Time: 0:31:45.287487\n",
      "Epoch 22: Validation loss = 0.035570366155243914 Time: 0:33:13.954785\n",
      "Epoch 23: Validation loss = 0.0341356204991935 Time: 0:34:43.771428\n",
      "Epoch 24: Validation loss = 0.03325282231768492 Time: 0:36:06.325213\n",
      "Epoch 25: Validation loss = 0.03098411321735785 Time: 0:37:32.054593\n",
      "Epoch 26: Validation loss = 0.03055185498008823 Time: 0:38:43.868310\n",
      "Epoch 27: Validation loss = 0.03092751798862957 Time: 0:40:04.411940\n",
      "Epoch 28: Validation loss = 0.030055198853907363 Time: 0:41:28.406280\n",
      "Epoch 29: Validation loss = 0.03107968353555281 Time: 0:42:48.915839\n",
      "Epoch 30: Validation loss = 0.03109231920707956 Time: 0:44:14.388307\n",
      "Epoch 31: Validation loss = 0.029987225805076033 Time: 0:45:37.688487\n",
      "Epoch 32: Validation loss = 0.028839165070393077 Time: 0:46:57.408955\n",
      "Epoch 33: Validation loss = 0.029299365851016286 Time: 0:48:21.572540\n",
      "Epoch 34: Validation loss = 0.028997955341199023 Time: 0:49:41.921551\n",
      "Epoch 35: Validation loss = 0.028620881027706848 Time: 0:51:01.698908\n",
      "Epoch 36: Validation loss = 0.028825660567024604 Time: 0:52:23.354294\n",
      "Epoch 37: Validation loss = 0.030880490662200936 Time: 0:53:46.573018\n",
      "Epoch 38: Validation loss = 0.029443872801477183 Time: 0:55:14.206921\n",
      "Epoch 39: Validation loss = 0.027980656431170908 Time: 0:56:43.588894\n",
      "Setting learning rate to 3.0e-04\n",
      "Epoch 0: Validation loss = 0.026084832965500182 Time: 0:01:13.996968\n",
      "Epoch 1: Validation loss = 0.026287210358446042 Time: 0:02:38.669027\n",
      "Epoch 2: Validation loss = 0.02555490910080288 Time: 0:04:01.927588\n",
      "Epoch 3: Validation loss = 0.025249137432086514 Time: 0:05:17.061823\n",
      "Epoch 4: Validation loss = 0.025334389393171876 Time: 0:06:45.559555\n",
      "Epoch 5: Validation loss = 0.02524547372925235 Time: 0:08:12.390048\n",
      "Epoch 6: Validation loss = 0.024973014843782972 Time: 0:09:34.315324\n",
      "Epoch 7: Validation loss = 0.024992521231155286 Time: 0:11:02.374621\n",
      "Epoch 8: Validation loss = 0.025150696005387413 Time: 0:12:22.037601\n",
      "Epoch 9: Validation loss = 0.02432226101803286 Time: 0:13:45.449922\n",
      "Epoch 10: Validation loss = 0.024607718539998033 Time: 0:15:19.892806\n",
      "Epoch 11: Validation loss = 0.02484957215050765 Time: 0:16:40.365430\n",
      "Epoch 12: Validation loss = 0.024911834721000316 Time: 0:17:56.935754\n",
      "Epoch 13: Validation loss = 0.025130732912184147 Time: 0:19:20.172866\n",
      "Epoch 14: Validation loss = 0.024299680093212237 Time: 0:20:38.533142\n",
      "Epoch 15: Validation loss = 0.024091515796013388 Time: 0:21:50.222428\n",
      "Epoch 16: Validation loss = 0.024227930431406183 Time: 0:23:12.871248\n",
      "Epoch 17: Validation loss = 0.024541308187884723 Time: 0:24:34.148354\n",
      "Epoch 18: Validation loss = 0.023661346700458948 Time: 0:25:49.317210\n",
      "Epoch 19: Validation loss = 0.024243246482160082 Time: 0:27:08.661605\n",
      "Epoch 20: Validation loss = 0.023992969236627085 Time: 0:28:29.163264\n",
      "Epoch 21: Validation loss = 0.023779115497031045 Time: 0:29:50.588814\n",
      "Epoch 22: Validation loss = 0.023833817111929216 Time: 0:31:09.782798\n",
      "Epoch 23: Validation loss = 0.02367720699508941 Time: 0:32:36.080877\n",
      "Epoch 24: Validation loss = 0.025211559220739265 Time: 0:33:59.489494\n",
      "Epoch 25: Validation loss = 0.023685824307362463 Time: 0:35:19.215964\n",
      "Epoch 26: Validation loss = 0.02359958524519337 Time: 0:36:44.331449\n",
      "Epoch 27: Validation loss = 0.023518339691389056 Time: 0:38:07.875424\n",
      "Epoch 28: Validation loss = 0.023734818876100405 Time: 0:39:32.558746\n",
      "Epoch 29: Validation loss = 0.023596548125641513 Time: 0:40:50.599267\n",
      "Epoch 30: Validation loss = 0.023870724416651067 Time: 0:42:14.131686\n",
      "Epoch 31: Validation loss = 0.02411842713235552 Time: 0:43:39.565105\n",
      "Epoch 32: Validation loss = 0.023665220970607675 Time: 0:44:52.798383\n",
      "Epoch 33: Validation loss = 0.02383289814264218 Time: 0:46:05.625320\n",
      "Epoch 34: Validation loss = 0.02395980058573746 Time: 0:47:31.640929\n",
      "Epoch 35: Validation loss = 0.02381440659648351 Time: 0:48:52.016759\n",
      "Epoch 36: Validation loss = 0.02312868313412602 Time: 0:50:13.806349\n",
      "Epoch 37: Validation loss = 0.02318455748630012 Time: 0:51:34.753284\n",
      "Epoch 38: Validation loss = 0.023315932465349132 Time: 0:52:55.761851\n",
      "Epoch 39: Validation loss = 0.023616291853512574 Time: 0:54:24.654659\n",
      "Setting learning rate to 1.0e-04\n",
      "Epoch 0: Validation loss = 0.02252331409722263 Time: 0:01:24.939995\n",
      "Epoch 1: Validation loss = 0.0225424601436862 Time: 0:02:53.729322\n",
      "Epoch 2: Validation loss = 0.02211850789372525 Time: 0:04:12.823321\n",
      "Epoch 3: Validation loss = 0.022187752519459692 Time: 0:05:30.731308\n",
      "Epoch 4: Validation loss = 0.022836309861037775 Time: 0:06:56.864138\n",
      "Epoch 5: Validation loss = 0.022127318379150933 Time: 0:08:13.678119\n",
      "Epoch 6: Validation loss = 0.022139975375852723 Time: 0:09:43.278188\n",
      "Epoch 7: Validation loss = 0.021969126378556938 Time: 0:10:59.159028\n",
      "Epoch 8: Validation loss = 0.022341949794951254 Time: 0:12:14.841093\n",
      "Epoch 9: Validation loss = 0.022103562554218397 Time: 0:13:32.345937\n",
      "Epoch 10: Validation loss = 0.02219727929089472 Time: 0:15:15.662241\n",
      "Epoch 11: Validation loss = 0.022145470529915993 Time: 0:16:49.903698\n",
      "Epoch 12: Validation loss = 0.0222320607393994 Time: 0:18:32.765256\n",
      "Epoch 13: Validation loss = 0.02207627108539744 Time: 0:19:55.827010\n",
      "Epoch 14: Validation loss = 0.02213002134130392 Time: 0:21:21.430780\n",
      "Epoch 15: Validation loss = 0.022197100086098116 Time: 0:22:48.135383\n",
      "Epoch 16: Validation loss = 0.022328292487990155 Time: 0:24:15.541054\n",
      "Epoch 17: Validation loss = 0.022610100401831854 Time: 0:25:40.083069\n",
      "Epoch 18: Validation loss = 0.02202828090421151 Time: 0:27:06.862073\n",
      "Epoch 19: Validation loss = 0.022101925493759302 Time: 0:28:32.529970\n",
      "Setting learning rate to 3.0e-05\n",
      "Epoch 0: Validation loss = 0.021758786149416776 Time: 0:01:22.988153\n",
      "Epoch 1: Validation loss = 0.021755953638364366 Time: 0:02:47.152570\n",
      "Epoch 2: Validation loss = 0.021791014703839373 Time: 0:04:11.899552\n",
      "Epoch 3: Validation loss = 0.021656827188496337 Time: 0:05:35.556080\n",
      "Epoch 4: Validation loss = 0.021958438601471706 Time: 0:06:58.358564\n",
      "Epoch 5: Validation loss = 0.021703612100853052 Time: 0:08:25.952679\n",
      "Epoch 6: Validation loss = 0.021782712727022483 Time: 0:09:51.184674\n",
      "Epoch 7: Validation loss = 0.021858064527237507 Time: 0:11:16.456608\n",
      "Epoch 8: Validation loss = 0.021718546687156216 Time: 0:12:43.682743\n",
      "Epoch 9: Validation loss = 0.02168176823788257 Time: 0:14:05.477537\n",
      "Epoch 10: Validation loss = 0.02178929637211645 Time: 0:15:27.451826\n",
      "Epoch 11: Validation loss = 0.021612387908702076 Time: 0:16:51.900777\n",
      "Epoch 12: Validation loss = 0.021550772996552576 Time: 0:18:17.825383\n",
      "Epoch 13: Validation loss = 0.02167787965953895 Time: 0:19:41.335290\n",
      "Epoch 14: Validation loss = 0.02150385983888516 Time: 0:21:04.287294\n",
      "Epoch 15: Validation loss = 0.02165480257251518 Time: 0:22:26.817906\n",
      "Epoch 16: Validation loss = 0.02163558984233547 Time: 0:23:50.799982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Validation loss = 0.021602727107217702 Time: 0:25:14.002489\n",
      "Epoch 18: Validation loss = 0.021398711292044743 Time: 0:26:36.488489\n",
      "Epoch 19: Validation loss = 0.021503997819704346 Time: 0:28:02.322757\n",
      "Setting learning rate to 1.0e-05\n",
      "Epoch 0: Validation loss = 0.02130557982232464 Time: 0:01:27.579731\n",
      "Epoch 1: Validation loss = 0.021379325710460726 Time: 0:02:57.511570\n",
      "Epoch 2: Validation loss = 0.021323835587396783 Time: 0:04:24.144836\n",
      "Epoch 3: Validation loss = 0.021352291990559834 Time: 0:05:47.490886\n",
      "Epoch 4: Validation loss = 0.02142687045295877 Time: 0:07:09.576468\n",
      "Epoch 5: Validation loss = 0.021319470333634887 Time: 0:08:35.636303\n",
      "Epoch 6: Validation loss = 0.021442389520985344 Time: 0:10:31.074790\n",
      "Epoch 7: Validation loss = 0.021379857342510925 Time: 0:11:57.284256\n",
      "Epoch 8: Validation loss = 0.02141284086839399 Time: 0:13:33.848459\n",
      "Epoch 9: Validation loss = 0.02138708472532033 Time: 0:14:53.365591\n",
      "Epoch 10: Validation loss = 0.021390188274547788 Time: 0:16:10.063238\n",
      "Epoch 11: Validation loss = 0.02143572575729906 Time: 0:17:28.810758\n",
      "Epoch 12: Validation loss = 0.021320343488836994 Time: 0:18:45.249707\n",
      "Epoch 13: Validation loss = 0.021269894530693074 Time: 0:20:09.686399\n",
      "Epoch 14: Validation loss = 0.02135717081986685 Time: 0:21:29.245179\n",
      "Epoch 15: Validation loss = 0.021423983069780002 Time: 0:22:53.183843\n",
      "Epoch 16: Validation loss = 0.021326006998895773 Time: 0:24:16.742484\n",
      "Epoch 17: Validation loss = 0.021224437521165308 Time: 0:25:36.738163\n",
      "Epoch 18: Validation loss = 0.021232450262155093 Time: 0:27:00.831393\n",
      "Epoch 19: Validation loss = 0.0212418001777782 Time: 0:28:23.353919\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "#epochs_list = [7, 5, 3, 2, 2]\n",
    "epochs_list = [40, 40, 20, 20, 20]\n",
    "lrs = [1e-3, 3e-4, 1e-4, 3e-5, 1e-5]\n",
    "for ii, epochs in enumerate(epochs_list):\n",
    "    print('Setting learning rate to %.1e' % lrs[ii])\n",
    "    opt = optim.Adam(model.parameters(), lr=lrs[ii])\n",
    "    #opt = optim.SGD(model.parameters(), lr=lrs[ii], momentum=0.9, nesterov=True)\n",
    "    #opt = optim.RMSprop(model.parameters(), lr=lrs[ii], momentum=0.9)\n",
    "    fit(epochs, model, loss_func, opt, train_dl, valid_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting learning rate to 1.0e-04\n",
      "Epoch 0: Validation loss = 0.02181655763103809 Time: 0:01:28.823996\n",
      "Epoch 1: Validation loss = 0.021788695071809937 Time: 0:02:58.289258\n",
      "Epoch 2: Validation loss = 0.021777302539102105 Time: 0:04:34.490480\n",
      "Epoch 3: Validation loss = 0.021781825925848482 Time: 0:06:06.166328\n",
      "Epoch 4: Validation loss = 0.021664511358028285 Time: 0:07:34.262131\n",
      "Epoch 5: Validation loss = 0.0216313482754231 Time: 0:09:04.327506\n",
      "Epoch 6: Validation loss = 0.021566813050706016 Time: 0:10:34.405740\n",
      "Epoch 7: Validation loss = 0.021837298927279022 Time: 0:11:59.836071\n",
      "Epoch 8: Validation loss = 0.0218041683337725 Time: 0:13:27.172105\n",
      "Epoch 9: Validation loss = 0.02185063744266292 Time: 0:14:43.244104\n",
      "Epoch 10: Validation loss = 0.021691754626885332 Time: 0:16:25.038445\n",
      "Epoch 11: Validation loss = 0.022247426614047584 Time: 0:17:41.637821\n",
      "Epoch 12: Validation loss = 0.021994135919378724 Time: 0:19:07.191488\n",
      "Epoch 13: Validation loss = 0.022026749790858176 Time: 0:20:36.542156\n",
      "Epoch 14: Validation loss = 0.021825499637528216 Time: 0:21:58.051940\n",
      "Epoch 15: Validation loss = 0.02169171361403246 Time: 0:23:25.085200\n",
      "Epoch 16: Validation loss = 0.021738663186510826 Time: 0:24:50.815824\n",
      "Epoch 17: Validation loss = 0.02172866844480266 Time: 0:26:06.197937\n",
      "Epoch 18: Validation loss = 0.021725486774080503 Time: 0:27:18.884416\n",
      "Epoch 19: Validation loss = 0.021296620618422912 Time: 0:28:39.876392\n",
      "Epoch 20: Validation loss = 0.021357758005254197 Time: 0:30:17.587771\n",
      "Epoch 21: Validation loss = 0.021538000599573753 Time: 0:31:47.737706\n",
      "Epoch 22: Validation loss = 0.021720272141981443 Time: 0:33:09.233501\n",
      "Epoch 23: Validation loss = 0.021575454628466315 Time: 0:34:33.016827\n",
      "Epoch 24: Validation loss = 0.021425463812173154 Time: 0:35:57.095664\n",
      "Epoch 25: Validation loss = 0.02149167636855339 Time: 0:37:14.862066\n",
      "Epoch 26: Validation loss = 0.02134121546187485 Time: 0:38:37.006201\n",
      "Epoch 27: Validation loss = 0.021413477157475196 Time: 0:39:57.836764\n",
      "Epoch 28: Validation loss = 0.021313090320252318 Time: 0:41:19.901034\n",
      "Epoch 29: Validation loss = 0.021438962892018142 Time: 0:42:43.419618\n",
      "Epoch 30: Validation loss = 0.02133864515234104 Time: 0:44:06.163389\n",
      "Epoch 31: Validation loss = 0.02137400668686672 Time: 0:45:31.191462\n",
      "Epoch 32: Validation loss = 0.021487205881186845 Time: 0:47:14.615570\n",
      "Epoch 33: Validation loss = 0.02148969084150092 Time: 0:48:42.520863\n",
      "Epoch 34: Validation loss = 0.021375889463453736 Time: 0:50:11.514355\n",
      "Epoch 35: Validation loss = 0.021348147532462804 Time: 0:51:42.017080\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-32560f142c41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#opt = optim.SGD(model.parameters(), lr=lrs[ii], momentum=0.9, nesterov=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#opt = optim.RMSprop(model.parameters(), lr=lrs[ii], momentum=0.9)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/LTH/Examensarbete/lth_thesis_project/my_nn_modules.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, model, loss_func, opt, train_dl, valid_dl, device)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'in-100-200-100-2-100-200-100-out'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/LTH/Examensarbete/lth_thesis_project/my_nn_modules.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, loss_func, xb, yb, opt)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mde1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastairoot/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-36326543b253>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-36326543b253>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mde4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mde3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mde2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mde1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastairoot/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastairoot/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastairoot/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "#epochs_list = [7, 5, 3, 2, 2]\n",
    "epochs_list = [40, 40, 20, 20, 20]\n",
    "lrs = [1e-4, 3e-5, 1e-5, 3e-6, 1e-6]\n",
    "for ii, epochs in enumerate(epochs_list):\n",
    "    print('Setting learning rate to %.1e' % lrs[ii])\n",
    "    opt = optim.Adam(model.parameters(), lr=lrs[ii])\n",
    "    #opt = optim.SGD(model.parameters(), lr=lrs[ii], momentum=0.9, nesterov=True)\n",
    "    #opt = optim.RMSprop(model.parameters(), lr=lrs[ii], momentum=0.9)\n",
    "    fit(epochs, model, loss_func, opt, train_dl, valid_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model for later inference (if training is to be continued another saving method is recommended)\n",
    "#save_path = './models/AE_2D_v50_loss0021.pt'\n",
    "#torch.save(model.state_dict(), save_path)\n",
    "# model_big = AE_big()\n",
    "# model_big.load_state_dict(torch.load(save_path))\n",
    "# model_big.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a few tensors, still normalized\n",
    "print('Comparing input and output:')\n",
    "for ii in np.arange(100, 105):\n",
    "    data = valid_ds.tensors[0][ii]\n",
    "    pred = model(data)\n",
    "    print('Inp:', data)\n",
    "    print('Out:', pred)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a few tensors, now not normalized\n",
    "print('Comparing input and output:')\n",
    "for ii in np.arange(100, 105):\n",
    "    data = valid_ds.tensors[0][ii]\n",
    "    pred = model(data).detach().numpy()\n",
    "    pred = np.multiply(pred, train_std.values)\n",
    "    pred = np.add(pred, train_mean.values)\n",
    "    data = np.multiply(data, train_std.values)\n",
    "    data = np.add(data, train_mean.values)\n",
    "    print('Inp:', data)\n",
    "    print('Out:', pred)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "unit_list = ['[GeV]', '[rad]', '[rad]', '[GeV]']\n",
    "variable_list = [r'$p_T$', r'$\\eta$', r'$\\phi$', r'$E$']\n",
    "line_style = ['--', '-']\n",
    "colors = ['orange', 'c']\n",
    "markers = ['*', 's']\n",
    "\n",
    "\n",
    "# Histograms\n",
    "idxs = (0, 100000)  # Choose events to compare\n",
    "data = torch.tensor(test_x[idxs[0]:idxs[1]].values)\n",
    "pred = model(data).detach().numpy()\n",
    "pred = np.multiply(pred, train_std.values)\n",
    "pred = np.add(pred, train_mean.values)\n",
    "data = np.multiply(data, train_std.values)\n",
    "data = np.add(data, train_mean.values)\n",
    "\n",
    "alph = 0.8\n",
    "n_bins = 50\n",
    "for kk in np.arange(4):\n",
    "    plt.figure(kk + 4)\n",
    "    n_hist_data, bin_edges, _ = plt.hist(data[:, kk], color=colors[1], label='Input', alpha=1, bins=n_bins)\n",
    "    n_hist_pred, _, _ = plt.hist(pred[:, kk], color=colors[0], label='Output', alpha=alph, bins=bin_edges)\n",
    "    plt.suptitle(train.columns[kk])\n",
    "    plt.xlabel(variable_list[kk] + ' ' + unit_list[kk])\n",
    "    plt.ylabel('Number of events')\n",
    "    plt.legend()\n",
    "    ms.sciy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot input on top of output\n",
    "idxs = (0, 100)  # Choose events to compare\n",
    "data = torch.tensor(test_x[idxs[0]:idxs[1]].values)\n",
    "pred = model(data).detach().numpy()\n",
    "pred = np.multiply(pred, train_std.values)\n",
    "pred = np.add(pred, train_mean.values)\n",
    "data = np.multiply(data, train_std.values)\n",
    "data = np.add(data, train_mean.values)\n",
    "\n",
    "for kk in np.arange(4):\n",
    "    plt.figure(kk)\n",
    "    plt.plot(data[:, kk], color=colors[1], label='Input', linestyle=line_style[1], marker=markers[1])\n",
    "    plt.plot(pred[:, kk], color=colors[0], label='Output', linestyle=line_style[0], marker=markers[0])\n",
    "    plt.suptitle(train.columns[kk])\n",
    "    plt.xlabel('Event')\n",
    "    plt.ylabel(variable_list[kk] + ' ' + unit_list[kk])\n",
    "    plt.legend()\n",
    "    ms.sciy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot input on top of output\n",
    "idxs = (0, int(1e5))  # Choose events to compare\n",
    "data = torch.tensor(test_x[idxs[0]:idxs[1]].values)\n",
    "latent = model.encode(data).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in np.arange(latent.shape[1]):\n",
    "    plt.figure()\n",
    "    plt.hist(latent[:, ii], label='$z_%d$' % (ii + 1), color='m')\n",
    "    plt.suptitle('Latent variable #%d' % (ii + 1))\n",
    "    plt.legend()\n",
    "    ms.sciy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mksz = 1\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(latent[:, 0], latent[:, 1], s=mksz)\n",
    "plt.xlabel(r'$z_1$')\n",
    "plt.ylabel(r'$z_2$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.7 (fastairoot)",
   "language": "python",
   "name": "fastairoot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
