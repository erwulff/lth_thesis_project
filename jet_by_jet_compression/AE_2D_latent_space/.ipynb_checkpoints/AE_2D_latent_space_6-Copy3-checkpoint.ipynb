{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jet Compression using an Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "BIN = '../../'\n",
    "sys.path.append(BIN)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from my_nn_modules import AE_big, get_data, fit\n",
    "\n",
    "import my_matplotlib_style as ms\n",
    "mpl.rc_file(BIN + 'my_matplotlib_rcparams')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "force_cpu = False\n",
    "\n",
    "if force_cpu:\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pT</th>\n",
       "      <th>eta</th>\n",
       "      <th>phi</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1367643</td>\n",
       "      <td>300.752869</td>\n",
       "      <td>0.118391</td>\n",
       "      <td>-1.460827</td>\n",
       "      <td>303.719818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1739612</td>\n",
       "      <td>79.819145</td>\n",
       "      <td>4.535507</td>\n",
       "      <td>-1.185196</td>\n",
       "      <td>3722.832764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>546066</td>\n",
       "      <td>220.472305</td>\n",
       "      <td>1.314261</td>\n",
       "      <td>-0.943992</td>\n",
       "      <td>440.195190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213212</td>\n",
       "      <td>74.533775</td>\n",
       "      <td>0.010658</td>\n",
       "      <td>-0.424795</td>\n",
       "      <td>74.770332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150544</td>\n",
       "      <td>220.668121</td>\n",
       "      <td>2.432910</td>\n",
       "      <td>-2.308348</td>\n",
       "      <td>1266.681030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>574837</td>\n",
       "      <td>159.841782</td>\n",
       "      <td>0.731125</td>\n",
       "      <td>-1.150598</td>\n",
       "      <td>207.133514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1171687</td>\n",
       "      <td>306.125305</td>\n",
       "      <td>0.702473</td>\n",
       "      <td>0.437615</td>\n",
       "      <td>385.713013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1608254</td>\n",
       "      <td>189.011673</td>\n",
       "      <td>-1.387443</td>\n",
       "      <td>0.490634</td>\n",
       "      <td>403.126709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1618830</td>\n",
       "      <td>194.996719</td>\n",
       "      <td>-1.022815</td>\n",
       "      <td>-1.560437</td>\n",
       "      <td>306.534515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>637947</td>\n",
       "      <td>186.887146</td>\n",
       "      <td>-0.621282</td>\n",
       "      <td>-0.465523</td>\n",
       "      <td>226.002701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pT       eta       phi            E\n",
       "1367643  300.752869  0.118391 -1.460827   303.719818\n",
       "1739612   79.819145  4.535507 -1.185196  3722.832764\n",
       "546066   220.472305  1.314261 -0.943992   440.195190\n",
       "213212    74.533775  0.010658 -0.424795    74.770332\n",
       "150544   220.668121  2.432910 -2.308348  1266.681030\n",
       "574837   159.841782  0.731125 -1.150598   207.133514\n",
       "1171687  306.125305  0.702473  0.437615   385.713013\n",
       "1608254  189.011673 -1.387443  0.490634   403.126709\n",
       "1618830  194.996719 -1.022815 -1.560437   306.534515\n",
       "637947   186.887146 -0.621282 -0.465523   226.002701"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "train = pd.read_pickle(BIN + 'processed_data/train.pkl')\n",
    "test = pd.read_pickle(BIN + 'processed_data/test.pkl')\n",
    "\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing and splitting into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "train_mean = train.mean()\n",
    "train_std = train.std()\n",
    "\n",
    "train = (train - train_mean) / train_std\n",
    "# Is this the right way to normalize? (only using train mean and std to normalize both train and test)\n",
    "test = (test - train_mean) / train_std\n",
    "\n",
    "train_x = train\n",
    "test_x = test\n",
    "train_y = train_x  # y = x since we are building and AE\n",
    "test_y = test_x\n",
    "\n",
    "train_ds = TensorDataset(torch.tensor(train_x.values), torch.tensor(train_y.values))\n",
    "valid_ds = TensorDataset(torch.tensor(test_x.values), torch.tensor(test_y.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(input, target, size_average=None, reduce=None, reduction='mean'):\n",
    "    # type: (Tensor, Tensor, Optional[bool], Optional[bool], str) -> Tensor\n",
    "    r\"\"\"mse_loss(input, target, size_average=None, reduce=None, reduction='mean') -> Tensor\n",
    "\n",
    "    Measures the element-wise mean squared error.\n",
    "\n",
    "    See :class:`~torch.nn.MSELoss` for details.\n",
    "    \"\"\"\n",
    "    if not (target.size() == input.size()):\n",
    "        warnings.warn(\"Using a target size ({}) that is different to the input size ({}). \"\n",
    "                      \"This will likely lead to incorrect results due to broadcasting. \"\n",
    "                      \"Please ensure they have the same size.\".format(target.size(), input.size()),\n",
    "                      stacklevel=2)\n",
    "    if size_average is not None or reduce is not None:\n",
    "        reduction = _Reduction.legacy_get_string(size_average, reduce)\n",
    "\n",
    "    ret = (input - target) ** 2\n",
    "    factor = torch.full(ret.size(), 1)\n",
    "    factor[:, 2] = 2.4\n",
    "    ret = ret * factor\n",
    "    if reduction != 'none':\n",
    "        ret = torch.mean(ret) if reduction == 'mean' else torch.sum(ret)\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 256  # batch size\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "loss_func = nn.MSELoss()\n",
    "loss_func = mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE_2D_v100(nn.Module):\n",
    "    def __init__(self, n_features=4):\n",
    "        super(AE_2D_v100, self).__init__()\n",
    "        self.en1 = nn.Linear(n_features, 100)\n",
    "        self.en2 = nn.Linear(100, 100)\n",
    "        self.en3 = nn.Linear(100, 100)\n",
    "        self.en4 = nn.Linear(100, 2)\n",
    "        self.de1 = nn.Linear(2, 100)\n",
    "        self.de2 = nn.Linear(100, 100)\n",
    "        self.de3 = nn.Linear(100, 100)\n",
    "        self.de4 = nn.Linear(100, n_features)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.en4(self.tanh(self.en3(self.tanh(self.en2(self.tanh(self.en1(x)))))))\n",
    "\n",
    "    def decode(self, x):\n",
    "        return self.de4(self.tanh(self.de3(self.tanh(self.de2(self.tanh(self.de1(self.tanh(x))))))))\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        return self.decode(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = len(train.loc[0])\n",
    "model = AE_2D_v100(n_features=n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting learning rate to 1.0e-03\n",
      "Epoch 0: Validation loss = 0.10715715437662698 Time: 0:02:07.825716\n",
      "Epoch 1: Validation loss = 0.08520913226633017 Time: 0:03:44.623826\n",
      "Epoch 2: Validation loss = 0.07719197941080594 Time: 0:05:21.820441\n",
      "Epoch 3: Validation loss = 0.06980059940911831 Time: 0:06:58.180364\n",
      "Epoch 4: Validation loss = 0.07601545871071194 Time: 0:08:38.674303\n",
      "Epoch 5: Validation loss = 0.06799713101155862 Time: 0:10:21.265588\n",
      "Epoch 6: Validation loss = 0.05873262408653547 Time: 0:11:59.064033\n",
      "Epoch 7: Validation loss = 0.052787435395288816 Time: 0:13:44.040238\n",
      "Epoch 8: Validation loss = 0.04665405955833874 Time: 0:15:24.272842\n",
      "Epoch 9: Validation loss = 0.0476494089195543 Time: 0:17:11.642743\n",
      "Epoch 10: Validation loss = 0.06562708492934717 Time: 0:18:53.802103\n",
      "Epoch 11: Validation loss = 0.050778616915632346 Time: 0:20:25.645725\n",
      "Epoch 12: Validation loss = 0.06679719881466906 Time: 0:22:02.698729\n",
      "Epoch 13: Validation loss = 0.06097566848592058 Time: 0:23:42.195912\n",
      "Epoch 14: Validation loss = 0.06145797695158475 Time: 0:25:17.425527\n",
      "Epoch 15: Validation loss = 0.058342990491238235 Time: 0:26:58.373912\n",
      "Epoch 16: Validation loss = 0.07102633478674307 Time: 0:28:49.997278\n",
      "Epoch 17: Validation loss = 0.07819844841490967 Time: 0:30:43.564575\n",
      "Epoch 18: Validation loss = 0.07186137514949258 Time: 0:32:34.328913\n",
      "Epoch 19: Validation loss = 0.05986858928183222 Time: 0:34:22.332926\n",
      "Epoch 20: Validation loss = 0.07417838381996875 Time: 0:36:02.065722\n",
      "Epoch 21: Validation loss = 0.06892651957397788 Time: 0:37:42.679977\n",
      "Epoch 22: Validation loss = 0.06151692114773123 Time: 0:39:08.136633\n",
      "Epoch 23: Validation loss = 0.09143361870066292 Time: 0:40:45.473705\n",
      "Epoch 24: Validation loss = 0.05791465900203142 Time: 0:42:24.220242\n",
      "Epoch 25: Validation loss = 0.07226927142695791 Time: 0:44:03.689981\n",
      "Epoch 26: Validation loss = 0.060757055539415496 Time: 0:45:42.445322\n",
      "Epoch 27: Validation loss = 0.06311161794740008 Time: 0:47:15.447027\n",
      "Epoch 28: Validation loss = 0.05308582370801482 Time: 0:48:59.052757\n",
      "Epoch 29: Validation loss = 0.05810137480526926 Time: 0:50:30.973436\n",
      "Epoch 30: Validation loss = 0.08254261282710292 Time: 0:52:04.847629\n",
      "Epoch 31: Validation loss = 0.06796291859132152 Time: 0:53:45.393020\n",
      "Epoch 32: Validation loss = 0.05957834492677412 Time: 0:55:27.477713\n",
      "Epoch 33: Validation loss = 0.06128505509558651 Time: 0:57:10.706675\n",
      "Epoch 34: Validation loss = 0.06465170283396547 Time: 0:58:44.965916\n",
      "Epoch 35: Validation loss = 0.24807186391272157 Time: 1:00:19.794463\n",
      "Epoch 36: Validation loss = 0.0951109457465001 Time: 1:01:53.822776\n",
      "Epoch 37: Validation loss = 0.07313992474743279 Time: 1:03:34.976903\n",
      "Epoch 38: Validation loss = 0.06898828768334564 Time: 1:05:17.886510\n",
      "Epoch 39: Validation loss = 0.07463265479062432 Time: 1:06:54.511553\n",
      "Setting learning rate to 3.0e-04\n",
      "Epoch 0: Validation loss = 0.06101895354768694 Time: 0:01:40.432040\n",
      "Epoch 1: Validation loss = 0.061239747058906925 Time: 0:03:18.547675\n",
      "Epoch 2: Validation loss = 0.05732975257782856 Time: 0:05:08.994588\n",
      "Epoch 3: Validation loss = 0.05750436570995144 Time: 0:06:42.512082\n",
      "Epoch 4: Validation loss = 0.05471083206317699 Time: 0:08:13.931025\n",
      "Epoch 5: Validation loss = 0.05130089815319444 Time: 0:09:52.722355\n",
      "Epoch 6: Validation loss = 0.052077901563485296 Time: 0:11:18.975062\n",
      "Epoch 7: Validation loss = 0.04943022270377504 Time: 0:12:52.620650\n",
      "Epoch 8: Validation loss = 0.05051872413230838 Time: 0:14:29.483121\n",
      "Epoch 9: Validation loss = 0.05096776268174611 Time: 0:16:02.879885\n",
      "Epoch 10: Validation loss = 0.05445077450890432 Time: 0:17:32.082521\n",
      "Epoch 11: Validation loss = 0.05254262445195365 Time: 0:19:11.902513\n",
      "Epoch 12: Validation loss = 0.050829139959587065 Time: 0:20:40.576747\n",
      "Epoch 13: Validation loss = 0.0499497599452193 Time: 0:22:23.756483\n",
      "Epoch 14: Validation loss = 0.048947995210024874 Time: 0:24:01.814200\n",
      "Epoch 15: Validation loss = 0.048012657759314285 Time: 0:25:35.507452\n",
      "Epoch 16: Validation loss = 0.047874203036049376 Time: 0:27:18.214965\n",
      "Epoch 17: Validation loss = 0.048072533711731945 Time: 0:28:59.917435\n",
      "Epoch 18: Validation loss = 0.04752847031877076 Time: 0:30:31.129655\n",
      "Epoch 19: Validation loss = 0.04675735410248793 Time: 0:32:13.029108\n",
      "Epoch 20: Validation loss = 0.04619779469767929 Time: 0:33:49.739323\n",
      "Epoch 21: Validation loss = 0.045703004302095666 Time: 0:35:14.763281\n",
      "Epoch 22: Validation loss = 0.044327834157478235 Time: 0:36:46.969899\n",
      "Epoch 23: Validation loss = 0.04354984174307518 Time: 0:38:27.166157\n",
      "Epoch 24: Validation loss = 0.04156303498647678 Time: 0:40:03.141972\n",
      "Epoch 25: Validation loss = 0.043803307252456236 Time: 0:41:39.105865\n",
      "Epoch 26: Validation loss = 0.04048507583616957 Time: 0:43:15.985999\n",
      "Epoch 27: Validation loss = 0.038878184505921315 Time: 0:45:03.893861\n",
      "Epoch 28: Validation loss = 0.0389209233362146 Time: 0:46:44.039538\n",
      "Epoch 29: Validation loss = 0.03894544378894019 Time: 0:48:21.372740\n",
      "Epoch 30: Validation loss = 0.03747294888769514 Time: 0:49:54.017215\n",
      "Epoch 31: Validation loss = 0.03625258057858769 Time: 0:51:31.974115\n",
      "Epoch 32: Validation loss = 0.03757212997128713 Time: 0:53:11.727058\n",
      "Epoch 33: Validation loss = 0.035843316025278016 Time: 0:54:48.714888\n",
      "Epoch 34: Validation loss = 0.03669237354629468 Time: 0:56:16.160366\n",
      "Epoch 35: Validation loss = 0.03714112853627268 Time: 0:57:48.043280\n",
      "Epoch 36: Validation loss = 0.037608269106032245 Time: 0:59:49.366097\n",
      "Epoch 37: Validation loss = 0.034280302115736946 Time: 1:01:50.170587\n",
      "Epoch 38: Validation loss = 0.03374246881340587 Time: 1:03:36.911104\n",
      "Epoch 39: Validation loss = 0.037561961725784375 Time: 1:05:17.488550\n",
      "Setting learning rate to 1.0e-04\n",
      "Epoch 0: Validation loss = 0.0328494225003415 Time: 0:01:43.141364\n",
      "Epoch 1: Validation loss = 0.03221724538969862 Time: 0:03:26.385864\n",
      "Epoch 2: Validation loss = 0.03227356499691575 Time: 0:05:06.615552\n",
      "Epoch 3: Validation loss = 0.031965482357649386 Time: 0:06:49.688241\n",
      "Epoch 4: Validation loss = 0.03225283545042329 Time: 0:08:29.784765\n",
      "Epoch 5: Validation loss = 0.031655203349286384 Time: 0:10:08.969307\n",
      "Epoch 6: Validation loss = 0.03182083810158243 Time: 0:11:48.645919\n",
      "Epoch 7: Validation loss = 0.032127978687758775 Time: 0:13:27.963816\n",
      "Epoch 8: Validation loss = 0.031370491144006196 Time: 0:15:07.098967\n",
      "Epoch 9: Validation loss = 0.03106587902445409 Time: 0:16:51.043156\n",
      "Epoch 10: Validation loss = 0.03191879089112999 Time: 0:18:32.414669\n",
      "Epoch 11: Validation loss = 0.03137355691304072 Time: 0:20:15.453598\n",
      "Epoch 12: Validation loss = 0.030719218301199287 Time: 0:21:52.436694\n",
      "Epoch 13: Validation loss = 0.030131422687342962 Time: 0:23:31.301744\n",
      "Epoch 14: Validation loss = 0.030066848917447073 Time: 0:25:13.072636\n",
      "Epoch 15: Validation loss = 0.030506437066457594 Time: 0:26:52.376291\n",
      "Epoch 16: Validation loss = 0.0313838111258111 Time: 0:28:31.117834\n",
      "Epoch 17: Validation loss = 0.02989384011634068 Time: 0:30:09.046787\n",
      "Epoch 18: Validation loss = 0.029569515814816014 Time: 0:31:48.109838\n",
      "Epoch 19: Validation loss = 0.03126251867795164 Time: 0:33:29.630293\n",
      "Setting learning rate to 3.0e-05\n",
      "Epoch 0: Validation loss = 0.0290294600396791 Time: 0:01:36.032478\n",
      "Epoch 1: Validation loss = 0.028761944686013688 Time: 0:03:20.073518\n",
      "Epoch 2: Validation loss = 0.029121167123376774 Time: 0:05:06.402242\n",
      "Epoch 3: Validation loss = 0.028914082500967303 Time: 0:06:49.694859\n",
      "Epoch 4: Validation loss = 0.028820832309287184 Time: 0:08:27.241718\n",
      "Epoch 5: Validation loss = 0.02857359311609199 Time: 0:09:59.686547\n",
      "Epoch 6: Validation loss = 0.028662475460351538 Time: 0:12:16.139124\n",
      "Epoch 7: Validation loss = 0.02888596082362609 Time: 0:13:59.459605\n",
      "Epoch 8: Validation loss = 0.02891855023523243 Time: 0:15:49.549869\n",
      "Epoch 9: Validation loss = 0.028926893855632633 Time: 0:17:23.961930\n",
      "Epoch 10: Validation loss = 0.029069558988817724 Time: 0:18:52.210552\n",
      "Epoch 11: Validation loss = 0.02870675815785578 Time: 0:20:21.677186\n",
      "Epoch 12: Validation loss = 0.028777680868152612 Time: 0:22:01.867698\n",
      "Epoch 13: Validation loss = 0.028821921042315027 Time: 0:23:37.472993\n",
      "Epoch 14: Validation loss = 0.02880698465417958 Time: 0:25:17.364869\n",
      "Epoch 15: Validation loss = 0.028753234476598385 Time: 0:26:52.764151\n",
      "Epoch 16: Validation loss = 0.028679217868932447 Time: 0:28:31.470027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Validation loss = 0.028826525231272236 Time: 0:30:12.715062\n",
      "Epoch 18: Validation loss = 0.028677206208826425 Time: 0:31:57.320332\n",
      "Epoch 19: Validation loss = 0.02867468887602695 Time: 0:33:44.799972\n",
      "Setting learning rate to 1.0e-05\n",
      "Epoch 0: Validation loss = 0.028511774212693165 Time: 0:01:51.671814\n",
      "Epoch 1: Validation loss = 0.0287195306564537 Time: 0:03:38.696864\n",
      "Epoch 2: Validation loss = 0.028866213287170227 Time: 0:05:24.204203\n",
      "Epoch 3: Validation loss = 0.028831930792911686 Time: 0:07:13.088939\n",
      "Epoch 4: Validation loss = 0.028972612178567968 Time: 0:08:56.517294\n",
      "Epoch 5: Validation loss = 0.028712953232543883 Time: 0:10:39.726211\n",
      "Epoch 6: Validation loss = 0.028524498217811625 Time: 0:12:26.834245\n",
      "Epoch 7: Validation loss = 0.028641679951842785 Time: 0:14:06.239001\n",
      "Epoch 8: Validation loss = 0.028837425765680137 Time: 0:15:44.764095\n",
      "Epoch 9: Validation loss = 0.028725909130305732 Time: 0:17:31.910289\n",
      "Epoch 10: Validation loss = 0.028623213746200013 Time: 0:19:07.689270\n",
      "Epoch 11: Validation loss = 0.02854694436557079 Time: 0:20:52.714503\n",
      "Epoch 12: Validation loss = 0.028742337619076547 Time: 0:22:24.527023\n",
      "Epoch 13: Validation loss = 0.02856672013977056 Time: 0:23:49.920074\n",
      "Epoch 14: Validation loss = 0.028824686019789807 Time: 0:25:27.910045\n",
      "Epoch 15: Validation loss = 0.02862292089226685 Time: 0:27:19.920447\n",
      "Epoch 16: Validation loss = 0.028550940354450525 Time: 0:29:02.267938\n",
      "Epoch 17: Validation loss = 0.028645537091419277 Time: 0:30:39.492400\n",
      "Epoch 18: Validation loss = 0.028468745451934507 Time: 0:32:21.411477\n",
      "Epoch 19: Validation loss = 0.028531824704332923 Time: 0:33:53.627033\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "#epochs_list = [7, 5, 3, 2, 2]\n",
    "epochs_list = [40, 40, 20, 20, 20]\n",
    "lrs = [1e-3, 3e-4, 1e-4, 3e-5, 1e-5]\n",
    "for ii, epochs in enumerate(epochs_list):\n",
    "    print('Setting learning rate to %.1e' % lrs[ii])\n",
    "    opt = optim.Adam(model.parameters(), lr=lrs[ii])\n",
    "    #opt = optim.SGD(model.parameters(), lr=lrs[ii], momentum=0.9, nesterov=True)\n",
    "    #opt = optim.RMSprop(model.parameters(), lr=lrs[ii], momentum=0.9)\n",
    "    fit(epochs, model, loss_func, opt, train_dl, valid_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting learning rate to 1.0e-04\n",
      "Epoch 0: Validation loss = 0.029498209481903716 Time: 0:01:35.521629\n",
      "Epoch 1: Validation loss = 0.029518394898326278 Time: 0:03:11.895488\n",
      "Epoch 2: Validation loss = 0.030685875466933445 Time: 0:04:52.572418\n",
      "Epoch 3: Validation loss = 0.029901059797897835 Time: 0:06:29.298219\n",
      "Epoch 4: Validation loss = 0.030063812897673854 Time: 0:08:09.411302\n",
      "Epoch 5: Validation loss = 0.029402771854688 Time: 0:10:12.697034\n",
      "Epoch 6: Validation loss = 0.029806307585448617 Time: 0:11:56.013013\n",
      "Epoch 7: Validation loss = 0.030436819391876417 Time: 0:13:48.475972\n",
      "Epoch 8: Validation loss = 0.029929202914537937 Time: 0:15:20.619372\n",
      "Epoch 9: Validation loss = 0.02933105469612895 Time: 0:16:42.457148\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-32560f142c41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#opt = optim.SGD(model.parameters(), lr=lrs[ii], momentum=0.9, nesterov=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#opt = optim.RMSprop(model.parameters(), lr=lrs[ii], momentum=0.9)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/LTH/Examensarbete/lth_thesis_project/my_nn_modules.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, model, loss_func, opt, train_dl, valid_dl, device)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'in-100-200-100-2-100-200-100-out'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/LTH/Examensarbete/lth_thesis_project/my_nn_modules.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, loss_func, xb, yb, opt)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mde1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastairoot/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-29abafe5f654>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-29abafe5f654>\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastairoot/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastairoot/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastairoot/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "#epochs_list = [7, 5, 3, 2, 2]\n",
    "epochs_list = [40, 40, 20, 20, 20]\n",
    "lrs = [1e-4, 3e-5, 1e-5, 3e-6, 1e-6]\n",
    "for ii, epochs in enumerate(epochs_list):\n",
    "    print('Setting learning rate to %.1e' % lrs[ii])\n",
    "    opt = optim.Adam(model.parameters(), lr=lrs[ii])\n",
    "    #opt = optim.SGD(model.parameters(), lr=lrs[ii], momentum=0.9, nesterov=True)\n",
    "    #opt = optim.RMSprop(model.parameters(), lr=lrs[ii], momentum=0.9)\n",
    "    fit(epochs, model, loss_func, opt, train_dl, valid_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model for later inference (if training is to be continued another saving method is recommended)\n",
    "#save_path = './models/AE_2D_v100_loss0029.pt'\n",
    "#torch.save(model.state_dict(), save_path)\n",
    "# model_big = AE_big()\n",
    "# model_big.load_state_dict(torch.load(save_path))\n",
    "# model_big.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a few tensors, still normalized\n",
    "print('Comparing input and output:')\n",
    "for ii in np.arange(100, 105):\n",
    "    data = valid_ds.tensors[0][ii]\n",
    "    pred = model(data)\n",
    "    print('Inp:', data)\n",
    "    print('Out:', pred)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a few tensors, now not normalized\n",
    "print('Comparing input and output:')\n",
    "for ii in np.arange(100, 105):\n",
    "    data = valid_ds.tensors[0][ii]\n",
    "    pred = model(data).detach().numpy()\n",
    "    pred = np.multiply(pred, train_std.values)\n",
    "    pred = np.add(pred, train_mean.values)\n",
    "    data = np.multiply(data, train_std.values)\n",
    "    data = np.add(data, train_mean.values)\n",
    "    print('Inp:', data)\n",
    "    print('Out:', pred)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "unit_list = ['[GeV]', '[rad]', '[rad]', '[GeV]']\n",
    "variable_list = [r'$p_T$', r'$\\eta$', r'$\\phi$', r'$E$']\n",
    "line_style = ['--', '-']\n",
    "colors = ['orange', 'c']\n",
    "markers = ['*', 's']\n",
    "\n",
    "\n",
    "# Histograms\n",
    "idxs = (0, 100000)  # Choose events to compare\n",
    "data = torch.tensor(test_x[idxs[0]:idxs[1]].values)\n",
    "pred = model(data).detach().numpy()\n",
    "pred = np.multiply(pred, train_std.values)\n",
    "pred = np.add(pred, train_mean.values)\n",
    "data = np.multiply(data, train_std.values)\n",
    "data = np.add(data, train_mean.values)\n",
    "\n",
    "alph = 0.8\n",
    "n_bins = 50\n",
    "for kk in np.arange(4):\n",
    "    plt.figure(kk + 4)\n",
    "    n_hist_data, bin_edges, _ = plt.hist(data[:, kk], color=colors[1], label='Input', alpha=1, bins=n_bins)\n",
    "    n_hist_pred, _, _ = plt.hist(pred[:, kk], color=colors[0], label='Output', alpha=alph, bins=bin_edges)\n",
    "    plt.suptitle(train.columns[kk])\n",
    "    plt.xlabel(variable_list[kk] + ' ' + unit_list[kk])\n",
    "    plt.ylabel('Number of events')\n",
    "    plt.legend()\n",
    "    ms.sciy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot input on top of output\n",
    "idxs = (0, 100)  # Choose events to compare\n",
    "data = torch.tensor(test_x[idxs[0]:idxs[1]].values)\n",
    "pred = model(data).detach().numpy()\n",
    "pred = np.multiply(pred, train_std.values)\n",
    "pred = np.add(pred, train_mean.values)\n",
    "data = np.multiply(data, train_std.values)\n",
    "data = np.add(data, train_mean.values)\n",
    "\n",
    "for kk in np.arange(4):\n",
    "    plt.figure(kk)\n",
    "    plt.plot(data[:, kk], color=colors[1], label='Input', linestyle=line_style[1], marker=markers[1])\n",
    "    plt.plot(pred[:, kk], color=colors[0], label='Output', linestyle=line_style[0], marker=markers[0])\n",
    "    plt.suptitle(train.columns[kk])\n",
    "    plt.xlabel('Event')\n",
    "    plt.ylabel(variable_list[kk] + ' ' + unit_list[kk])\n",
    "    plt.legend()\n",
    "    ms.sciy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot input on top of output\n",
    "idxs = (0, int(1e5))  # Choose events to compare\n",
    "data = torch.tensor(test_x[idxs[0]:idxs[1]].values)\n",
    "latent = model.encode(data).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in np.arange(latent.shape[1]):\n",
    "    plt.figure()\n",
    "    plt.hist(latent[:, ii], label='$z_%d$' % (ii + 1), color='m')\n",
    "    plt.suptitle('Latent variable #%d' % (ii + 1))\n",
    "    plt.legend()\n",
    "    ms.sciy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mksz = 1\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(latent[:, 0], latent[:, 1], s=mksz)\n",
    "plt.xlabel(r'$z_1$')\n",
    "plt.ylabel(r'$z_2$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.7 (fastairoot)",
   "language": "python",
   "name": "fastairoot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
