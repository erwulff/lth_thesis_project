{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jet Compression using an Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "BIN = '../../'\n",
    "sys.path.append(BIN)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from my_nn_modules import AE_big, get_data, fit\n",
    "\n",
    "import my_matplotlib_style as ms\n",
    "mpl.rc_file(BIN + 'my_matplotlib_rcparams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "force_cpu = False\n",
    "\n",
    "if force_cpu:\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pT</th>\n",
       "      <th>eta</th>\n",
       "      <th>phi</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1367643</td>\n",
       "      <td>300.752869</td>\n",
       "      <td>0.118391</td>\n",
       "      <td>-1.460827</td>\n",
       "      <td>303.719818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1739612</td>\n",
       "      <td>79.819145</td>\n",
       "      <td>4.535507</td>\n",
       "      <td>-1.185196</td>\n",
       "      <td>3722.832764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>546066</td>\n",
       "      <td>220.472305</td>\n",
       "      <td>1.314261</td>\n",
       "      <td>-0.943992</td>\n",
       "      <td>440.195190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213212</td>\n",
       "      <td>74.533775</td>\n",
       "      <td>0.010658</td>\n",
       "      <td>-0.424795</td>\n",
       "      <td>74.770332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150544</td>\n",
       "      <td>220.668121</td>\n",
       "      <td>2.432910</td>\n",
       "      <td>-2.308348</td>\n",
       "      <td>1266.681030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>574837</td>\n",
       "      <td>159.841782</td>\n",
       "      <td>0.731125</td>\n",
       "      <td>-1.150598</td>\n",
       "      <td>207.133514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1171687</td>\n",
       "      <td>306.125305</td>\n",
       "      <td>0.702473</td>\n",
       "      <td>0.437615</td>\n",
       "      <td>385.713013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1608254</td>\n",
       "      <td>189.011673</td>\n",
       "      <td>-1.387443</td>\n",
       "      <td>0.490634</td>\n",
       "      <td>403.126709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1618830</td>\n",
       "      <td>194.996719</td>\n",
       "      <td>-1.022815</td>\n",
       "      <td>-1.560437</td>\n",
       "      <td>306.534515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>637947</td>\n",
       "      <td>186.887146</td>\n",
       "      <td>-0.621282</td>\n",
       "      <td>-0.465523</td>\n",
       "      <td>226.002701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pT       eta       phi            E\n",
       "1367643  300.752869  0.118391 -1.460827   303.719818\n",
       "1739612   79.819145  4.535507 -1.185196  3722.832764\n",
       "546066   220.472305  1.314261 -0.943992   440.195190\n",
       "213212    74.533775  0.010658 -0.424795    74.770332\n",
       "150544   220.668121  2.432910 -2.308348  1266.681030\n",
       "574837   159.841782  0.731125 -1.150598   207.133514\n",
       "1171687  306.125305  0.702473  0.437615   385.713013\n",
       "1608254  189.011673 -1.387443  0.490634   403.126709\n",
       "1618830  194.996719 -1.022815 -1.560437   306.534515\n",
       "637947   186.887146 -0.621282 -0.465523   226.002701"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "train = pd.read_pickle(BIN + 'processed_data/train.pkl')\n",
    "test = pd.read_pickle(BIN + 'processed_data/test.pkl')\n",
    "\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing and splitting into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pT      20721.585938\n",
       "eta         4.785440\n",
       "phi         3.141583\n",
       "E      146259.562500\n",
       "dtype: float32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pT     226.349228\n",
       "eta     -0.021712\n",
       "phi      0.008840\n",
       "E      596.682495\n",
       "dtype: float32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "train_mean = train.mean()\n",
    "train_std = train.std()\n",
    "#train_max = np.max(train)\n",
    "\n",
    "train = (train - train_mean) / train_std\n",
    "#train = (train - train_mean) / train_max\n",
    "test = (test - train_mean) / train_std\n",
    "#test = (test - train_mean) / train_max\n",
    "\n",
    "train_x = train\n",
    "test_x = test\n",
    "train_y = train_x  # y = x since we are building and AE\n",
    "test_y = test_x\n",
    "\n",
    "train_ds = TensorDataset(torch.tensor(train_x.values), torch.tensor(train_y.values))\n",
    "valid_ds = TensorDataset(torch.tensor(test_x.values), torch.tensor(test_y.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 256  # batch size\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = len(train.loc[0])\n",
    "model_big = AE_big(n_features=n_features)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Training\n",
    "opt = optim.Adam(model_big.parameters(), lr=1e-3)\n",
    "epochs = 5\n",
    "train_losses, valid_losses = fit(epochs, model_big, loss_func, opt, train_dl, valid_dl, device)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.plot(train_losses, label='training loss')\n",
    "plt.plot(valid_losses, label='valid_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model_big.parameters(), lr=1e-3)\n",
    "epochs = 10\n",
    "summary_df = fit(epochs, model_big, loss_func, opt, train_dl, valid_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting learning rate to 1.0e-03\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4f0b44e72857>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Setting learning rate to %.1e'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_big\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mepoch_train_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_val_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_big\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mtrain_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_losses\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepoch_train_losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepoch_val_losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/LTH/Examensarbete/lth_thesis_project/my_nn_modules.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, model, loss_func, opt, train_dl, valid_dl, device)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         \u001b[0mepoch_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1009\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m             \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastairoot/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastairoot/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/fastairoot/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastairoot/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastairoot/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "epochs_list = [7, 5, 3, 2, 2]\n",
    "lrs = [1e-3, 3e-4, 1e-4, 3e-5, 1e-5]\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for ii, epochs in enumerate(epochs_list):\n",
    "    print('Setting learning rate to %.1e' % lrs[ii])\n",
    "    opt = optim.Adam(model_big.parameters(), lr=lrs[ii])\n",
    "    epoch_train_losses, epoch_val_losses = fit(epochs, model_big, loss_func, opt, train_dl, valid_dl, device)\n",
    "    train_losses = train_losses + epoch_train_losses\n",
    "    val_losses = val_losses + epoch_val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses[1:], marker='>', label='training loss')\n",
    "plt.plot(val_losses[1:], marker='>', label='valid_loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model for later inference (if training is to be continued another saving method is recommended)\n",
    "# save_path = './models/AE_big_model_loss48eneg6.pt'\n",
    "# torch.save(model_big.state_dict(), save_path)\n",
    "# model_big = AE_big()\n",
    "# model_big.load_state_dict(torch.load(save_path))\n",
    "# model_big.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_big.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a few tensors, still normalized\n",
    "print('Comparing input and output:')\n",
    "for ii in np.arange(100, 105):\n",
    "    data = valid_ds.tensors[0][ii]\n",
    "    pred = model_big(data)\n",
    "    print('Inp:', data)\n",
    "    print('Out:', pred)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a few tensors, now not normalized\n",
    "print('Comparing input and output:')\n",
    "for ii in np.arange(100, 105):\n",
    "    data = valid_ds.tensors[0][ii]\n",
    "    pred = model_big(data).detach().numpy()\n",
    "    pred = np.multiply(pred, train_std.values)\n",
    "#    pred = np.multiply(pred, train_max.values)\n",
    "    pred = np.add(pred, train_mean.values)\n",
    "    data = np.multiply(data, train_std.values)\n",
    "#    data = np.multiply(data, train_max.values)\n",
    "    data = np.add(data, train_mean.values)\n",
    "    print('Inp:', data)\n",
    "    print('Out:', pred)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "unit_list = ['[GeV]', '[rad]', '[rad]', '[GeV]']\n",
    "variable_list = [r'$p_T$', r'$\\eta$', r'$\\phi$', r'$E$']\n",
    "line_style = ['--', '-']\n",
    "colors = ['orange', 'c']\n",
    "markers = ['*', 's']\n",
    "\n",
    "\n",
    "# Histograms\n",
    "idxs = (0, 100000)  # Choose events to compare\n",
    "data = torch.tensor(test_x[idxs[0]:idxs[1]].values)\n",
    "pred = model_big(data).detach().numpy()\n",
    "pred = np.multiply(pred, train_std.values)\n",
    "#pred = np.multiply(pred, train_max.values)\n",
    "pred = np.add(pred, train_mean.values)\n",
    "data = np.multiply(data, train_std.values)\n",
    "#data = np.multiply(data, train_max.values)\n",
    "data = np.add(data, train_mean.values)\n",
    "\n",
    "alph = 0.8\n",
    "n_bins = 50\n",
    "for kk in np.arange(4):\n",
    "    plt.figure(kk + 4)\n",
    "    n_hist_data, bin_edges, _ = plt.hist(data[:, kk], color=colors[1], label='Input', alpha=1, bins=n_bins)\n",
    "    n_hist_pred, _, _ = plt.hist(pred[:, kk], color=colors[0], label='Output', alpha=alph, bins=bin_edges)\n",
    "    plt.suptitle(train.columns[kk])\n",
    "    plt.xlabel(variable_list[kk] + ' ' + unit_list[kk])\n",
    "    plt.ylabel('Number of events')\n",
    "    ms.sciy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot input on top of output\n",
    "idxs = (0, 100)  # Choose events to compare\n",
    "data = torch.tensor(test_x[idxs[0]:idxs[1]].values)\n",
    "pred = model_big(data).detach().numpy()\n",
    "pred = np.multiply(pred, train_std.values)\n",
    "#pred = np.multiply(pred, train_max.values)\n",
    "pred = np.add(pred, train_mean.values)\n",
    "data = np.multiply(data, train_std.values)\n",
    "#data = np.multiply(data, train_max.values)\n",
    "data = np.add(data, train_mean.values)\n",
    "\n",
    "for kk in np.arange(4):\n",
    "    plt.figure(kk)\n",
    "    plt.plot(data[:, kk], color=colors[1], label='Input', linestyle=line_style[1], marker=markers[1])\n",
    "    plt.plot(pred[:, kk], color=colors[0], label='Output', linestyle=line_style[0], marker=markers[0])\n",
    "    plt.suptitle(train.columns[kk])\n",
    "    plt.xlabel('Event')\n",
    "    plt.ylabel(variable_list[kk] + ' ' + unit_list[kk])\n",
    "    plt.legend()\n",
    "    ms.sciy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.7 (fastairoot)",
   "language": "python",
   "name": "fastairoot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
