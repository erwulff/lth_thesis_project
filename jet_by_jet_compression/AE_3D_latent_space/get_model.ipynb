{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jet Compression using an Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "BIN = '../../'\n",
    "sys.path.append(BIN)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from my_nn_modules import AE_big, get_data, fit\n",
    "\n",
    "import my_matplotlib_style as ms\n",
    "mpl.rc_file(BIN + 'my_matplotlib_rcparams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "force_cpu = False\n",
    "\n",
    "if force_cpu:\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pT</th>\n",
       "      <th>eta</th>\n",
       "      <th>phi</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1367643</td>\n",
       "      <td>300.752869</td>\n",
       "      <td>0.118391</td>\n",
       "      <td>-1.460827</td>\n",
       "      <td>303.719818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1739612</td>\n",
       "      <td>79.819145</td>\n",
       "      <td>4.535507</td>\n",
       "      <td>-1.185196</td>\n",
       "      <td>3722.832764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>546066</td>\n",
       "      <td>220.472305</td>\n",
       "      <td>1.314261</td>\n",
       "      <td>-0.943992</td>\n",
       "      <td>440.195190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213212</td>\n",
       "      <td>74.533775</td>\n",
       "      <td>0.010658</td>\n",
       "      <td>-0.424795</td>\n",
       "      <td>74.770332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150544</td>\n",
       "      <td>220.668121</td>\n",
       "      <td>2.432910</td>\n",
       "      <td>-2.308348</td>\n",
       "      <td>1266.681030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>574837</td>\n",
       "      <td>159.841782</td>\n",
       "      <td>0.731125</td>\n",
       "      <td>-1.150598</td>\n",
       "      <td>207.133514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1171687</td>\n",
       "      <td>306.125305</td>\n",
       "      <td>0.702473</td>\n",
       "      <td>0.437615</td>\n",
       "      <td>385.713013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1608254</td>\n",
       "      <td>189.011673</td>\n",
       "      <td>-1.387443</td>\n",
       "      <td>0.490634</td>\n",
       "      <td>403.126709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1618830</td>\n",
       "      <td>194.996719</td>\n",
       "      <td>-1.022815</td>\n",
       "      <td>-1.560437</td>\n",
       "      <td>306.534515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>637947</td>\n",
       "      <td>186.887146</td>\n",
       "      <td>-0.621282</td>\n",
       "      <td>-0.465523</td>\n",
       "      <td>226.002701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pT       eta       phi            E\n",
       "1367643  300.752869  0.118391 -1.460827   303.719818\n",
       "1739612   79.819145  4.535507 -1.185196  3722.832764\n",
       "546066   220.472305  1.314261 -0.943992   440.195190\n",
       "213212    74.533775  0.010658 -0.424795    74.770332\n",
       "150544   220.668121  2.432910 -2.308348  1266.681030\n",
       "574837   159.841782  0.731125 -1.150598   207.133514\n",
       "1171687  306.125305  0.702473  0.437615   385.713013\n",
       "1608254  189.011673 -1.387443  0.490634   403.126709\n",
       "1618830  194.996719 -1.022815 -1.560437   306.534515\n",
       "637947   186.887146 -0.621282 -0.465523   226.002701"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "train = pd.read_pickle(BIN + 'processed_data/train.pkl')\n",
    "test = pd.read_pickle(BIN + 'processed_data/test.pkl')\n",
    "\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing and splitting into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "train_mean = train.mean()\n",
    "train_std = train.std()\n",
    "\n",
    "train = (train - train_mean) / train_std\n",
    "# Is this the right way to normalize? (only using train mean and std to normalize both train and test)\n",
    "test = (test - train_mean) / train_std\n",
    "\n",
    "train_x = train\n",
    "test_x = test\n",
    "train_y = train_x  # y = x since we are building and AE\n",
    "test_y = test_x\n",
    "\n",
    "train_ds = TensorDataset(torch.tensor(train_x.values), torch.tensor(train_y.values))\n",
    "valid_ds = TensorDataset(torch.tensor(test_x.values), torch.tensor(test_y.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1550321, 4) (387581, 4)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 3.00000e+00, 1.04030e+04, 3.59260e+04, 3.38000e+04,\n",
       "        2.72110e+04, 2.97320e+04, 3.06360e+04, 2.32380e+04, 1.95780e+04,\n",
       "        1.89540e+04, 2.23020e+04, 3.10100e+04, 5.19450e+04, 7.94390e+04,\n",
       "        1.00168e+05, 1.11372e+05, 1.07613e+05, 9.42850e+04, 8.18850e+04,\n",
       "        7.18760e+04, 6.30080e+04, 5.41930e+04, 4.69800e+04, 4.12230e+04,\n",
       "        3.54680e+04, 3.08500e+04, 2.68230e+04, 2.36560e+04, 2.17670e+04,\n",
       "        2.05710e+04, 2.20510e+04, 2.32450e+04, 2.23020e+04, 1.97450e+04,\n",
       "        1.62720e+04, 1.41620e+04, 1.16070e+04, 9.93100e+03, 8.43000e+03,\n",
       "        7.24200e+03, 6.20900e+03, 5.38300e+03, 4.55800e+03, 3.99500e+03,\n",
       "        3.49300e+03, 2.94500e+03, 2.56500e+03, 2.31300e+03, 1.90800e+03,\n",
       "        1.72200e+03, 1.53600e+03, 1.36400e+03, 1.19300e+03, 1.05800e+03,\n",
       "        8.83000e+02, 7.95000e+02, 6.99000e+02, 6.96000e+02, 5.66000e+02,\n",
       "        4.93000e+02, 4.64000e+02, 4.15000e+02, 3.68000e+02, 3.60000e+02,\n",
       "        3.44000e+02, 2.57000e+02, 2.39000e+02, 2.33000e+02, 1.87000e+02]),\n",
       " array([-5. , -4.9, -4.8, -4.7, -4.6, -4.5, -4.4, -4.3, -4.2, -4.1, -4. ,\n",
       "        -3.9, -3.8, -3.7, -3.6, -3.5, -3.4, -3.3, -3.2, -3.1, -3. , -2.9,\n",
       "        -2.8, -2.7, -2.6, -2.5, -2.4, -2.3, -2.2, -2.1, -2. , -1.9, -1.8,\n",
       "        -1.7, -1.6, -1.5, -1.4, -1.3, -1.2, -1.1, -1. , -0.9, -0.8, -0.7,\n",
       "        -0.6, -0.5, -0.4, -0.3, -0.2, -0.1,  0. ,  0.1,  0.2,  0.3,  0.4,\n",
       "         0.5,  0.6,  0.7,  0.8,  0.9,  1. ,  1.1,  1.2,  1.3,  1.4,  1.5,\n",
       "         1.6,  1.7,  1.8,  1.9,  2. ,  2.1,  2.2,  2.3,  2.4,  2.5,  2.6,\n",
       "         2.7,  2.8,  2.9,  3. ,  3.1,  3.2,  3.3,  3.4,  3.5,  3.6,  3.7,\n",
       "         3.8,  3.9,  4. ,  4.1,  4.2,  4.3,  4.4,  4.5,  4.6,  4.7,  4.8,\n",
       "         4.9,  5. ], dtype=float32),\n",
       " <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train['pT'], bins=100, range=(-5, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 256  # batch size\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [4,8,6,4,3,4,6,8,4]\n",
    "n_layers = len(nodes)\n",
    "nodes[(n_layers // 2)]\n",
    "\n",
    "ins_n_outs = []\n",
    "en_modulelist = nn.ModuleList()\n",
    "de_modulelist = nn.ModuleList()\n",
    "for ii in range(n_layers // 2):\n",
    "    ins = nodes[ii]\n",
    "    outs = nodes[ii + 1]\n",
    "    ins_n_outs.append((ins, outs))\n",
    "    en_modulelist.append(nn.Linear(ins, outs))\n",
    "    en_modulelist.append(nn.Tanh())\n",
    "for ii in range(n_layers // 2):\n",
    "    ii += n_layers // 2\n",
    "    ins = nodes[ii]\n",
    "    outs = nodes[ii + 1]\n",
    "    de_modulelist.append(nn.Linear(ins, outs))\n",
    "    de_modulelist.append(nn.Tanh())\n",
    "    \n",
    "    \n",
    "encoder = nn.Sequential(en_modulelist)\n",
    "\n",
    "decoder = nn.Sequential(de_modulelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_param_string = ''\n",
    "for ii in nodes:\n",
    "                curr_param_string = curr_param_string + '_%d' %ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_4_8_6_4_3_4_6_8_4'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_param_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = 'abcd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abc'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): ModuleList(\n",
       "    (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=8, out_features=6, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=6, out_features=4, bias=True)\n",
       "    (5): Tanh()\n",
       "    (6): Linear(in_features=4, out_features=3, bias=True)\n",
       "    (7): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): ModuleList(\n",
       "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=4, out_features=6, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=6, out_features=8, bias=True)\n",
       "    (5): Tanh()\n",
       "    (6): Linear(in_features=8, out_features=4, bias=True)\n",
       "    (7): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE_bn(nn.Module):\n",
    "    def __init__(self, nodes, no_last_bias=False):\n",
    "        super(AE_bn, self).__init__()\n",
    "        n_layers = len(nodes)\n",
    "        ins_n_outs = []\n",
    "        en_modulelist = nn.ModuleList()\n",
    "        de_modulelist = nn.ModuleList()\n",
    "        for ii in range(n_layers // 2):\n",
    "            ins = nodes[ii]\n",
    "            outs = nodes[ii + 1]\n",
    "            ins_n_outs.append((ins, outs))\n",
    "            en_modulelist.append(nn.Linear(ins, outs))\n",
    "            en_modulelist.append(nn.Tanh())\n",
    "            en_modulelist.append(nn.BatchNorm1d(outs))\n",
    "        for ii in range(n_layers // 2):\n",
    "            ii += n_layers // 2\n",
    "            ins = nodes[ii]\n",
    "            outs = nodes[ii + 1]\n",
    "            de_modulelist.append(nn.Linear(ins, outs))\n",
    "            de_modulelist.append(nn.Tanh())\n",
    "            de_modulelist.append(nn.BatchNorm1d(outs))\n",
    "            \n",
    "        de_modulelist = de_modulelist[:-2]  # Remove Tanh activation and BatchNorm1d from output layer\n",
    "        if no_last_bias:\n",
    "            de_modulelist = de_modulelist[:-1]\n",
    "            de_modulelist.append(nn.Linear(nodes[-2], nodes[-1], bias=False))\n",
    "\n",
    "\n",
    "        self.encoder = nn.Sequential(*en_modulelist)\n",
    "\n",
    "        self.decoder = nn.Sequential(*de_modulelist)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "        \n",
    "    def decode(self, x):\n",
    "        return self.decoder(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.decode(self.encode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AE_bn(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Linear(in_features=8, out_features=6, bias=True)\n",
       "    (4): Tanh()\n",
       "    (5): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Linear(in_features=6, out_features=4, bias=True)\n",
       "    (7): Tanh()\n",
       "    (8): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Linear(in_features=4, out_features=3, bias=True)\n",
       "    (10): Tanh()\n",
       "    (11): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Linear(in_features=4, out_features=6, bias=True)\n",
       "    (4): Tanh()\n",
       "    (5): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Linear(in_features=6, out_features=8, bias=True)\n",
       "    (7): Tanh()\n",
       "    (8): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Linear(in_features=8, out_features=4, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myAE = AE_bn(nodes, no_last_bias=True)\n",
    "myAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE_basic(nn.Module):\n",
    "    def __init__(self, nodes, no_last_bias=False):\n",
    "        super(AE_basic, self).__init__()\n",
    "        n_layers = len(nodes)\n",
    "        ins_n_outs = []\n",
    "        en_modulelist = nn.ModuleList()\n",
    "        de_modulelist = nn.ModuleList()\n",
    "        for ii in range(n_layers // 2):\n",
    "            ins = nodes[ii]\n",
    "            outs = nodes[ii + 1]\n",
    "            ins_n_outs.append((ins, outs))\n",
    "            en_modulelist.append(nn.Linear(ins, outs))\n",
    "            en_modulelist.append(nn.Tanh())\n",
    "        for ii in range(n_layers // 2):\n",
    "            ii += n_layers // 2\n",
    "            ins = nodes[ii]\n",
    "            outs = nodes[ii + 1]\n",
    "            de_modulelist.append(nn.Linear(ins, outs))\n",
    "            de_modulelist.append(nn.Tanh())\n",
    "            \n",
    "        de_modulelist = de_modulelist[:-1]  # Remove Tanh activation from output layer\n",
    "        if no_last_bias:\n",
    "            de_modulelist = de_modulelist[:-1]\n",
    "            de_modulelist.append(nn.Linear(nodes[-2], nodes[-1], bias=False))\n",
    "\n",
    "        self.encoder = nn.Sequential(*en_modulelist)\n",
    "\n",
    "        self.decoder = nn.Sequential(*de_modulelist)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "        \n",
    "    def decode(self, x):\n",
    "        return self.decoder(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.decode(self.encode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "myAE = AE_basic(nodes, no_last_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AE_basic(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=8, out_features=6, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=6, out_features=4, bias=True)\n",
       "    (5): Tanh()\n",
       "    (6): Linear(in_features=4, out_features=3, bias=True)\n",
       "    (7): Tanh()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=4, out_features=6, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=6, out_features=8, bias=True)\n",
       "    (5): Tanh()\n",
       "    (6): Linear(in_features=8, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AE_basic(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting learning rate to 1.0e-03\n",
      "Epoch: 0 Train Loss: 2.396e-01 Val Loss: 8.184e-03, Time: 0:00:32.035541\n",
      "Epoch: 1 Train Loss: 2.629e-01 Val Loss: 2.777e-03, Time: 0:00:30.765149\n",
      "Epoch: 2 Train Loss: 2.841e-01 Val Loss: 1.636e-03, Time: 0:00:31.298818\n",
      "Epoch: 3 Train Loss: 3.045e-01 Val Loss: 9.892e-04, Time: 0:00:32.005582\n",
      "Epoch: 4 Train Loss: 3.245e-01 Val Loss: 6.708e-04, Time: 0:00:31.086475\n",
      "Epoch: 5 Train Loss: 3.440e-01 Val Loss: 4.923e-04, Time: 0:00:29.964064\n",
      "Epoch: 6 Train Loss: 3.634e-01 Val Loss: 4.244e-04, Time: 0:00:30.184789\n",
      "Training complete in 3m 37s\n",
      "Setting learning rate to 3.0e-04\n",
      "Epoch: 0 Train Loss: 1.910e-02 Val Loss: 3.524e-04, Time: 0:00:34.694439\n",
      "Epoch: 1 Train Loss: 3.813e-02 Val Loss: 3.480e-04, Time: 0:00:32.456886\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-33baa895df24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Setting learning rate to %.1e'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/LTH/Examensarbete/lth_thesis_project/my_nn_modules.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, model, loss_func, opt, train_dl, valid_dl, device)\u001b[0m\n\u001b[1;32m    934\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m             losses, nums = zip(\n\u001b[0;32m--> 936\u001b[0;31m                 \u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mxb_tmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb_tmp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m             )\n\u001b[1;32m    938\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunning_train_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/LTH/Examensarbete/lth_thesis_project/my_nn_modules.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    934\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m             losses, nums = zip(\n\u001b[0;32m--> 936\u001b[0;31m                 \u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mxb_tmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb_tmp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m             )\n\u001b[1;32m    938\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunning_train_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastairoot/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastairoot/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastairoot/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastairoot/lib/python3.7/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "epochs_list = [7, 5, 3, 2, 2]\n",
    "lrs = [1e-3, 3e-4, 1e-4, 3e-5, 1e-5]\n",
    "for ii, epochs in enumerate(epochs_list):\n",
    "    print('Setting learning rate to %.1e' % lrs[ii])\n",
    "    opt = optim.Adam(model.parameters(), lr=lrs[ii])\n",
    "    fit(epochs, model, loss_func, opt, train_dl, valid_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ericwulff/Documents/LTH/Examensarbete/lth_thesis_project/jet_by_jet_compression/AE_3D_latent_space'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for AE_basic:\n\tMissing key(s) in state_dict: \"encoder.0.weight\", \"encoder.0.bias\", \"encoder.2.weight\", \"encoder.2.bias\", \"encoder.4.weight\", \"encoder.4.bias\", \"encoder.6.weight\", \"encoder.6.bias\", \"decoder.0.weight\", \"decoder.0.bias\", \"decoder.2.weight\", \"decoder.2.bias\", \"decoder.4.weight\", \"decoder.4.bias\", \"decoder.6.weight\", \"decoder.6.bias\". \n\tUnexpected key(s) in state_dict: \"en1.weight\", \"en1.bias\", \"en2.weight\", \"en2.bias\", \"en3.weight\", \"en3.bias\", \"en4.weight\", \"en4.bias\", \"de1.weight\", \"de1.bias\", \"de2.weight\", \"de2.bias\", \"de3.weight\", \"de3.bias\", \"de4.weight\", \"de4.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-1d53814753a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# torch.save(model_big.state_dict(), save_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#model_big = AE_big()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#model_big.eval()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastairoot/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 845\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for AE_basic:\n\tMissing key(s) in state_dict: \"encoder.0.weight\", \"encoder.0.bias\", \"encoder.2.weight\", \"encoder.2.bias\", \"encoder.4.weight\", \"encoder.4.bias\", \"encoder.6.weight\", \"encoder.6.bias\", \"decoder.0.weight\", \"decoder.0.bias\", \"decoder.2.weight\", \"decoder.2.bias\", \"decoder.4.weight\", \"decoder.4.bias\", \"decoder.6.weight\", \"decoder.6.bias\". \n\tUnexpected key(s) in state_dict: \"en1.weight\", \"en1.bias\", \"en2.weight\", \"en2.bias\", \"en3.weight\", \"en3.bias\", \"en4.weight\", \"en4.bias\", \"de1.weight\", \"de1.bias\", \"de2.weight\", \"de2.bias\", \"de3.weight\", \"de3.bias\", \"de4.weight\", \"de4.bias\". "
     ]
    }
   ],
   "source": [
    "# saving the model for later inference (if training is to be continued another saving method is recommended)\n",
    "save_path = './models/AE_big_model_loss48eneg6.pt'\n",
    "# torch.save(model_big.state_dict(), save_path)\n",
    "#model_big = AE_big()\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "#model_big.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model.parameters(), lr=1e-4)\n",
    "fit(10, model, loss_func, opt, train_dl, valid_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model.parameters(), lr=1e-5)\n",
    "fit(10, model, loss_func, opt, train_dl, valid_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model.parameters(), lr=1e-5)\n",
    "fit(10, model, loss_func, opt, train_dl, valid_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model.parameters(), lr=3e-6)\n",
    "fit(10, model, loss_func, opt, train_dl, valid_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model.parameters(), lr=3e-6)\n",
    "fit(10, model, loss_func, opt, train_dl, valid_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model.parameters(), lr=1e-6)\n",
    "fit(10, model, loss_func, opt, train_dl, valid_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model.parameters(), lr=1e-6)\n",
    "fit(30, model, loss_func, opt, train_dl, valid_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model for later inference (if training is to be continued another saving method is recommended)\n",
    "#save_path = './models/AE_3D_v2_bs256_loss28eneg7.pt'\n",
    "#torch.save(model.state_dict(), save_path)\n",
    "# model_big = AE_big()\n",
    "# model_big.load_state_dict(torch.load(save_path))\n",
    "# model_big.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a few tensors, still normalized\n",
    "print('Comparing input and output:')\n",
    "for ii in np.arange(100, 105):\n",
    "    data = valid_ds.tensors[0][ii]\n",
    "    pred = model(data)\n",
    "    print('Inp:', data)\n",
    "    print('Out:', pred)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a few tensors, now not normalized\n",
    "print('Comparing input and output:')\n",
    "for ii in np.arange(100, 105):\n",
    "    data = valid_ds.tensors[0][ii]\n",
    "    pred = model(data).detach().numpy()\n",
    "    pred = np.multiply(pred, train_std.values)\n",
    "    pred = np.add(pred, train_mean.values)\n",
    "    data = np.multiply(data, train_std.values)\n",
    "    data = np.add(data, train_mean.values)\n",
    "    print('Inp:', data)\n",
    "    print('Out:', pred)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "unit_list = ['[GeV]', '[rad]', '[rad]', '[GeV]']\n",
    "variable_list = [r'$p_T$', r'$\\eta$', r'$\\phi$', r'$E$']\n",
    "line_style = ['--', '-']\n",
    "colors = ['orange', 'c']\n",
    "markers = ['*', 's']\n",
    "\n",
    "\n",
    "# Histograms\n",
    "idxs = (0, 100000)  # Choose events to compare\n",
    "data = torch.tensor(test_x[idxs[0]:idxs[1]].values)\n",
    "pred = model(data).detach().numpy()\n",
    "pred = np.multiply(pred, train_std.values)\n",
    "pred = np.add(pred, train_mean.values)\n",
    "data = np.multiply(data, train_std.values)\n",
    "data = np.add(data, train_mean.values)\n",
    "\n",
    "alph = 0.8\n",
    "n_bins = 50\n",
    "for kk in np.arange(4):\n",
    "    plt.figure(kk + 4)\n",
    "    n_hist_data, bin_edges, _ = plt.hist(data[:, kk], color=colors[1], label='Input', alpha=1, bins=n_bins)\n",
    "    n_hist_pred, _, _ = plt.hist(pred[:, kk], color=colors[0], label='Output', alpha=alph, bins=bin_edges)\n",
    "    plt.suptitle(train.columns[kk])\n",
    "    plt.xlabel(variable_list[kk] + ' ' + unit_list[kk])\n",
    "    plt.ylabel('Number of events')\n",
    "    ms.sciy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot input on top of output\n",
    "idxs = (0, 100)  # Choose events to compare\n",
    "data = torch.tensor(test_x[idxs[0]:idxs[1]].values)\n",
    "pred = model(data).detach().numpy()\n",
    "pred = np.multiply(pred, train_std.values)\n",
    "pred = np.add(pred, train_mean.values)\n",
    "data = np.multiply(data, train_std.values)\n",
    "data = np.add(data, train_mean.values)\n",
    "\n",
    "for kk in np.arange(4):\n",
    "    plt.figure(kk)\n",
    "    plt.plot(data[:, kk], color=colors[1], label='Input', linestyle=line_style[1], marker=markers[1])\n",
    "    plt.plot(pred[:, kk], color=colors[0], label='Output', linestyle=line_style[0], marker=markers[0])\n",
    "    plt.suptitle(train.columns[kk])\n",
    "    plt.xlabel('Event')\n",
    "    plt.ylabel(variable_list[kk] + ' ' + unit_list[kk])\n",
    "    plt.legend()\n",
    "    ms.sciy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot input on top of output\n",
    "idxs = (0, int(1.9e6))  # Choose events to compare\n",
    "data = torch.tensor(test_x[idxs[0]:idxs[1]].values)\n",
    "latent = model.encode(data).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in np.arange(latent.shape[1]):\n",
    "    plt.figure()\n",
    "    plt.hist(latent[:, ii], label='$z_%d$' % (ii + 1), color='m')\n",
    "    plt.suptitle('Latent variable #%d' % (ii + 1))\n",
    "    plt.legend()\n",
    "    ms.sciy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "idxs = (0, 10000)  # Choose events to compare\n",
    "data = torch.tensor(test_x[idxs[0]:idxs[1]].values)\n",
    "latent = model.encode(data).detach().numpy()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(latent[:, 0], latent[:, 1], latent[:, 2], s=1)\n",
    "ax.set_xlabel(r'$z_1$')\n",
    "ax.set_ylabel(r'$z_2$')\n",
    "ax.set_zlabel(r'$z_3$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mksz = 1\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(latent[:, 0], latent[:, 1], s=mksz)\n",
    "plt.xlabel(r'$z_1$')\n",
    "plt.ylabel(r'$z_2$')\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(latent[:, 0], latent[:, 2], s=mksz)\n",
    "plt.xlabel(r'$z_1$')\n",
    "plt.ylabel(r'$z_3$')\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(latent[:, 1], latent[:, 2], s=mksz)\n",
    "plt.xlabel(r'$z_2$')\n",
    "plt.ylabel(r'$z_3$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.7 (fastairoot)",
   "language": "python",
   "name": "fastairoot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
